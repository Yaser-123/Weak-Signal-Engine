<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #0e1117;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 600px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ooredoos-syntys-acquires-two-data-centers-in-qatar/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ooredoos-syntys-acquires-two-data-centers-in-qatar/", "physics": true, "shape": "dot", "size": 6, "title": "Ooredoo\u2019s Syntys acquires two data centers in Qatar. \u003cp\u003eTelco\u0027s data center spin-out acquires sites from Quantum Switch\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "label": "AI Energy Independence: Labs Building Private Onsite Power Grids", "physics": true, "shape": "dot", "size": 95, "title": "AI Energy Independence: Labs Building Private Onsite Power Grids (56 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/att-occupied-data-center-up-for-sale-in-alpharetta-georgia/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/att-occupied-data-center-up-for-sale-in-alpharetta-georgia/", "physics": true, "shape": "dot", "size": 6, "title": "AT\u0026T-occupied data center up for sale in Alpharetta, Georgia. \u003cp\u003eTelco set to stay in place for at least three more years\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-cfo-says-company-ended-2025-with-19gw-of-compute-scaled-revenue-at-same-speed/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-cfo-says-company-ended-2025-with-19gw-of-compute-scaled-revenue-at-same-speed/", "physics": true, "shape": "dot", "size": 6, "title": "OpenAI CFO says company ended 2025 with 1.9GW of compute, scaled revenue at same speed. \u003cp\u003eClaims a clear correlation between aggressive data center ramp-up and rising revenue\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/fuelcell-energy-partners-with-sdc-to-deploy-up-to-450mw-of-fuel-cells-across-data-centers-globally/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/fuelcell-energy-partners-with-sdc-to-deploy-up-to-450mw-of-fuel-cells-across-data-centers-globally/", "physics": true, "shape": "dot", "size": 6, "title": "FuelCell Energy partners with SDC to deploy up to 450MW of fuel cells across data centers globally. \u003cp\u003eClaim the system is well suited to AI data center power needs\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-launches-cloud-region-in-bangkok-thailand/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-launches-cloud-region-in-bangkok-thailand/", "physics": true, "shape": "dot", "size": 6, "title": "Google launches cloud region in Bangkok, Thailand. \u003cp\u003eCompany pledged $1bn investment in Thailand in 2024\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-pledges-to-pay-its-own-way-to-power-stargate-data-centers/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-pledges-to-pay-its-own-way-to-power-stargate-data-centers/", "physics": true, "shape": "dot", "size": 6, "title": "OpenAI pledges to \u201cpay its own way\u201d to power Stargate data centers. \u003cp\u003eIn an attempt to prevent electricity price increases for regular ratepayers\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/planned-project-atlas-data-center-campus-in-coweta-oklahoma-fails-to-secure-backing-from-planners/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/planned-project-atlas-data-center-campus-in-coweta-oklahoma-fails-to-secure-backing-from-planners/", "physics": true, "shape": "dot", "size": 6, "title": "Planned Project Atlas data center campus in Coweta, Oklahoma fails to secure backing from planners. \u003cp\u003eFinal decision to be made in February\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/gpuaas-provider-voltage-park-merges-with-cloud-platform-lightning-ai/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/gpuaas-provider-voltage-park-merges-with-cloud-platform-lightning-ai/", "physics": true, "shape": "dot", "size": 6, "title": "GPUaaS provider Voltage Park merges with cloud platform Lightning AI. \u003cp\u003eTwo combine to create an AI cloud offering\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vivopower-acquires-rights-to-25mw-data-center-in-uae/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vivopower-acquires-rights-to-25mw-data-center-in-uae/", "physics": true, "shape": "dot", "size": 6, "title": "VivoPower acquires rights to 25MW data center in UAE. \u003cp\u003eThe project has secured long-term power infrastructure\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cleanarc-partners-with-crow-holdings-for-245mw-campus-in-dallas-texas/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cleanarc-partners-with-crow-holdings-for-245mw-campus-in-dallas-texas/", "physics": true, "shape": "dot", "size": 6, "title": "CleanArc partners with Crow Holdings for 245MW campus in Dallas, Texas. \u003cp\u003eReal estate firm claims potential data center pipeline of 3GW\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/videos/dcdstudio-enabling-liquid-cooling-through-open-cdus-with-abishek-gupta-nvent/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/videos/dcdstudio-enabling-liquid-cooling-through-open-cdus-with-abishek-gupta-nvent/", "physics": true, "shape": "dot", "size": 6, "title": "DCD\u003eStudio: Enabling liquid cooling through Open CDUs, with Abishek Gupta, nVent. \u003cp\u003eKat Sullivan speaks with Abishek Gupta of nVent on OCP-driven cooling innovations, collaboration, and efficient designs to address rising power densities and evolving data center demands.\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/norways-asp-acquires-land-for-25mw-data-center-project-in-suldal/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/norways-asp-acquires-land-for-25mw-data-center-project-in-suldal/", "physics": true, "shape": "dot", "size": 6, "title": "Norway\u0027s ASP acquires land for 25MW data center project in Suldal. \u003cp\u003eLocal municipality greenlights land sale\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/g42-ceo-says-company-will-receive-first-ai-chip-shipments-within-months-to-support-initial-200mw-of-capacity-for-planned-stargate-cluster/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/g42-ceo-says-company-will-receive-first-ai-chip-shipments-within-months-to-support-initial-200mw-of-capacity-for-planned-stargate-cluster/", "physics": true, "shape": "dot", "size": 6, "title": "G42 CEO says company will receive first AI chip shipments \u201cwithin months\u201d to support initial 200MW of capacity for planned Stargate cluster. \u003cp\u003eComments made by Peng Xiao during an interview at Davos\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microgeo-satellite-operator-swissto12-secures-73m-in-funding/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microgeo-satellite-operator-swissto12-secures-73m-in-funding/", "physics": true, "shape": "dot", "size": 6, "title": "MicroGEO satellite operator Swissto12 secures \u20ac73m in funding. \u003cp\u003eFunds secured from ESA member states\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/goodman-files-to-develop-90mw-data-center-campus-in-sydney-australia-2/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/goodman-files-to-develop-90mw-data-center-campus-in-sydney-australia-2/", "physics": true, "shape": "dot", "size": 6, "title": "Goodman files to develop 90MW data center campus in Sydney, Australia. \u003cp\u003eCompany looks to replace former Coles warehouse with two-building development\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/upcloud-launches-data-center-region-in-norway/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/upcloud-launches-data-center-region-in-norway/", "physics": true, "shape": "dot", "size": 6, "title": "UpCloud launches data center region in Norway. \u003cp\u003eComes shortly after launching a location in Denmark\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/big-fiber-bypasses-tapped-out-bay-area-networks-with-dark-fiber-expansion/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/big-fiber-bypasses-tapped-out-bay-area-networks-with-dark-fiber-expansion/", "physics": true, "shape": "dot", "size": 6, "title": "Big Fiber bypasses \u0027tapped out\u0027 Bay Area networks with dark fiber expansion. \u003cp\u003eCoreSite\u0027s SV1 tenants gain access to high-speed, low-latency connectivity for data-heavy and AI workloads\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/product-news/inside-nibi-how-immersion-cooling-and-ai-scale-compute-are-changing-canadian-hpc/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/product-news/inside-nibi-how-immersion-cooling-and-ai-scale-compute-are-changing-canadian-hpc/", "physics": true, "shape": "dot", "size": 6, "title": "Sponsored: Inside Nibi: How immersion cooling and AI-scale compute are changing Canadian HPC. \u003cp\u003eNibi serves as a national platform for advanced research, enabling breakthroughs across disciplines while providing a practical reference for sustainable HPC design at scale\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/the-biggest-data-center-stories-of-2025/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/the-biggest-data-center-stories-of-2025/", "physics": true, "shape": "dot", "size": 6, "title": "The biggest data center stories of 2025. \u003cp\u003eHere\u2019s the news highlights of the biggest year in data centers\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/whitepapers/powering-the-future-of-us-data-centers/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/whitepapers/powering-the-future-of-us-data-centers/", "physics": true, "shape": "dot", "size": 6, "title": "Powering the future of US data centers. \u003cp\u003eHow electricity providers can overcome bottlenecks and supercharge growth\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-behind-1bn-data-center-in-little-rock-arkansas-report/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-behind-1bn-data-center-in-little-rock-arkansas-report/", "physics": true, "shape": "dot", "size": 6, "title": "Google behind $1bn data center in Little Rock, Arkansas - report. \u003cp\u003eDeveloper\u0027s identity has been a mystery for months\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/anger-over-plans-for-data-center-at-truman-brewery-in-londons-brick-lane/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/anger-over-plans-for-data-center-at-truman-brewery-in-londons-brick-lane/", "physics": true, "shape": "dot", "size": 6, "title": "Anger over plans for data center at Truman Brewery in London\u0027s Brick Lane. \u003cp\u003eResidents say proposed data center threatens to intensify environmental harms\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/digital-halo-secures-469m-in-financing-for-philippines-data-center-project/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/digital-halo-secures-469m-in-financing-for-philippines-data-center-project/", "physics": true, "shape": "dot", "size": 6, "title": "Digital Halo secures $46.9m in financing for Philippines data center project. \u003cp\u003eFinancing will be used to develop its MNL1 data center\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/2025-telco-talking-points-ai-fiber-frenzy-and-an-ma-boom/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/2025-telco-talking-points-ai-fiber-frenzy-and-an-ma-boom/", "physics": true, "shape": "dot", "size": 6, "title": "2025 telco talking points: AI, fiber frenzy, and an M\u0026A boom. \u003cp\u003eAI is reshaping the telecoms industry, but is it for better or worse?\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/furiosaai-seeking-a-500m-funding-round-ahead-of-anticipated-ipo-report/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/furiosaai-seeking-a-500m-funding-round-ahead-of-anticipated-ipo-report/", "physics": true, "shape": "dot", "size": 6, "title": "FuriosaAI seeking a $500m funding round ahead of anticipated IPO \u2013 report. \u003cp\u003eCompany expected to receive its first shipment of RNGD AI chips later this month\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#ff9500", "font": {"color": "white"}, "id": "collapsed_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "label": "+31 more", "physics": true, "shape": "box", "size": 12, "title": "This cluster has 31 more signals not shown in the graph.\nSelect the cluster below to view all 56 signals."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/meta-signs-176mwdc-solar-ppa-with-zelestra-in-texas/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/meta-signs-176mwdc-solar-ppa-with-zelestra-in-texas/", "physics": true, "shape": "dot", "size": 6, "title": "Meta signs 176MWdc solar PPA with Zelestra in Texas. \u003cp\u003eBrings the total contracted capacity between the two companies to 1.2GW\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tiktok-us-spin-off-finalized-led-by-oracle-silver-lake-and-mgx/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tiktok-us-spin-off-finalized-led-by-oracle-silver-lake-and-mgx/", "physics": true, "shape": "dot", "size": 6, "title": "TikTok US spin-off finalized, led by Oracle, Silver Lake, and MGX. \u003cp\u003eByteDance retains 19.9 percent stake\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/airbus-bids-to-standardize-5g-network-services-with-upnext-spaceran-system/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/airbus-bids-to-standardize-5g-network-services-with-upnext-spaceran-system/", "physics": true, "shape": "dot", "size": 6, "title": "Airbus bids to standardize 5G network services with UpNext SpaceRAN system. \u003cp\u003eAerospace giant\u0027s Euro-heavy testing consortium will analyse needs of 6G systems on-orbit\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/globalwafers-planning-to-further-expand-capacity-at-its-35bn-fab-in-sherman-texas/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/globalwafers-planning-to-further-expand-capacity-at-its-35bn-fab-in-sherman-texas/", "physics": true, "shape": "dot", "size": 6, "title": "GlobalWafers planning to further expand capacity at its $3.5bn fab in Sherman, Texas. \u003cp\u003eTaiwanese chipmaker made the decision following discussions with customers\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/first-of-its-kind-50mw-smr-powered-data-center-planned-in-uzbekistan/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/first-of-its-kind-50mw-smr-powered-data-center-planned-in-uzbekistan/", "physics": true, "shape": "dot", "size": 6, "title": "\u0027First-of-its-kind\u0027 50MW SMR-powered data center planned in Uzbekistan. \u003cp\u003eWill be first data center powered solely by an SMR, if it is built\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/kazakhstan-plans-data-center-valley-powered-by-coal/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/kazakhstan-plans-data-center-valley-powered-by-coal/", "physics": true, "shape": "dot", "size": 6, "title": "Kazakhstan plans data center valley powered by coal. \u003cp\u003eBut the nation has a limited data center footprint at the moment\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/leeds-uk-based-photonic-chip-startup-optalysys-raises-23m/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/leeds-uk-based-photonic-chip-startup-optalysys-raises-23m/", "physics": true, "shape": "dot", "size": 6, "title": "Leeds, UK-based photonic chip startup Optalysys raises \u00a323m. \u003cp\u003eFunding will be used to commercialize technology and support US expansion\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/eu-outlines-plans-to-phase-out-high-risk-vendors-in-network-infrastructure/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/eu-outlines-plans-to-phase-out-high-risk-vendors-in-network-infrastructure/", "physics": true, "shape": "dot", "size": 6, "title": "EU outlines plans to phase out high risk vendors in network infrastructure. \u003cp\u003eThe move is set to be a blow for Huawei and ZTE\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/dayone-targets-560mw-data-center-campus-outside-helsinki-finland/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/dayone-targets-560mw-data-center-campus-outside-helsinki-finland/", "physics": true, "shape": "dot", "size": 6, "title": "DayOne targets 560MW data center campus outside Helsinki, Finland. \u003cp\u003eCompany follows Lahti and Kouvola projects with one in Klaukkala\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/japans-i-net-opens-data-center-in-yokohama/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/japans-i-net-opens-data-center-in-yokohama/", "physics": true, "shape": "dot", "size": 6, "title": "Japan\u0027s I-Net opens data center in Yokohama. \u003cp\u003eAs company looks to decommission original facility\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bytedance-ramps-up-cloud-computing-offering-in-china/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bytedance-ramps-up-cloud-computing-offering-in-china/", "physics": true, "shape": "dot", "size": 6, "title": "ByteDance ramps up cloud computing offering in China. \u003cp\u003eCompany has been expanding its cloud team and undercutting rivals on prices\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bouygue/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bouygue/", "physics": true, "shape": "dot", "size": 6, "title": "Bouygues Telecom, Free-Iliad, and Orange in talks to scoop up Altice\u0027s French telco assets. \u003cp\u003eNegotiations are ongoing, but nothing has been agreed yet\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/e/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/e/", "physics": true, "shape": "dot", "size": 6, "title": "Exowatt launches business arm to deliver powered land and energy for hyperscale data centers. \u003cp\u003eExoRise will be underpinned by the company\u0027s solar + storage technology\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microsoft-wins-170m-cloud-contract-from-us-air-force/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microsoft-wins-170m-cloud-contract-from-us-air-force/", "physics": true, "shape": "dot", "size": 6, "title": "Microsoft wins $170m cloud contract from US Air Force. \u003cp\u003eContract awarded as part of the Cloud One Program\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/global-switch-signs-eight-year-ppa-with-rwe-to-power-docklands-data-center-in-london/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/global-switch-signs-eight-year-ppa-with-rwe-to-power-docklands-data-center-in-london/", "physics": true, "shape": "dot", "size": 6, "title": "Global Switch signs eight year PPA with RWE to power Docklands data center in London. \u003cp\u003eWill offtake power from a onshore wind project in Wales\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/humain-and-infra-set-up-12bn-financing-package-to-fund-250mw-of-data-center-space-in-saudi-arabia/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/humain-and-infra-set-up-12bn-financing-package-to-fund-250mw-of-data-center-space-in-saudi-arabia/", "physics": true, "shape": "dot", "size": 6, "title": "Humain and Infra set up $1.2bn financing package to fund 250MW of data center space in Saudi Arabia. \u003cp\u003eNon-binding agreement to fund digital infrastructure projects\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/telenor-sells-30-percent-stake-in-thailands-true-corporation-to-arise-digital-technology/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/telenor-sells-30-percent-stake-in-thailands-true-corporation-to-arise-digital-technology/", "physics": true, "shape": "dot", "size": 6, "title": "Telenor sells 30 percent stake in Thailand\u2019s True Corporation to Arise Digital Technology. \u003cp\u003eThe sale will net Telenor $3.9 billion\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11776v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11776v1", "physics": true, "shape": "dot", "size": 6, "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models. arXiv:2601.11776v1 Announce Type: cross \nAbstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "label": "Global Infrastructure: Massive Scaling of AI-Ready Data Centers", "physics": true, "shape": "dot", "size": 137, "title": "Global Infrastructure: Massive Scaling of AI-Ready Data Centers (909 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11778v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11778v1", "physics": true, "shape": "dot", "size": 6, "title": "Translation as a Scalable Proxy for Multilingual Evaluation. arXiv:2601.11778v1 Announce Type: cross \nAbstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving \u003e98% of the world\u0027s 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model\u0027s broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11801v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11801v1", "physics": true, "shape": "dot", "size": 6, "title": "RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models. arXiv:2601.11801v1 Announce Type: cross \nAbstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11854v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11854v1", "physics": true, "shape": "dot", "size": 6, "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System. arXiv:2601.11854v1 Announce Type: cross \nAbstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11868v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11868v1", "physics": true, "shape": "dot", "size": 6, "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces. arXiv:2601.11868v1 Announce Type: cross \nAbstract: AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ ."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12061v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12061v1", "physics": true, "shape": "dot", "size": 6, "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation. arXiv:2601.12061v1 Announce Type: cross \nAbstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11859v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11859v1", "physics": true, "shape": "dot", "size": 6, "title": "Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization. arXiv:2601.11859v1 Announce Type: cross \nAbstract: The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11863v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11863v1", "physics": true, "shape": "dot", "size": 6, "title": "Utilizing Metadata for Better Retrieval-Augmented Generation. arXiv:2601.11863v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11895v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11895v1", "physics": true, "shape": "dot", "size": 6, "title": "DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models. arXiv:2601.11895v1 Announce Type: cross \nAbstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11907v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11907v1", "physics": true, "shape": "dot", "size": 6, "title": "Towards Airborne Object Detection: A Deep Learning Analysis. arXiv:2601.11907v1 Announce Type: cross \nAbstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11913v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11913v1", "physics": true, "shape": "dot", "size": 6, "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding. arXiv:2601.11913v1 Announce Type: cross \nAbstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM\u0027s hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11920v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11920v1", "physics": true, "shape": "dot", "size": 6, "title": "Enhancing LLM-Based Data Annotation with Error Decomposition. arXiv:2601.11920v1 Announce Type: cross \nAbstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11956v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11956v1", "physics": true, "shape": "dot", "size": 6, "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence. arXiv:2601.11956v1 Announce Type: cross \nAbstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs\u0027 reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11960v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11960v1", "physics": true, "shape": "dot", "size": 6, "title": "R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning. arXiv:2601.11960v1 Announce Type: cross \nAbstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11969v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11969v1", "physics": true, "shape": "dot", "size": 6, "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models. arXiv:2601.11969v1 Announce Type: cross \nAbstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11977v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11977v1", "physics": true, "shape": "dot", "size": 6, "title": "One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints. arXiv:2601.11977v1 Announce Type: cross \nAbstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11995v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11995v1", "physics": true, "shape": "dot", "size": 6, "title": "Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs. arXiv:2601.11995v1 Announce Type: cross \nAbstract: Learning robust audio-visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences - background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. For example, a video labeled \"train\" might also contain motorcycle audio and visual, because \"motorcycle\" is not the chosen annotation; standard methods treat these co-occurrences as negatives to true motorcycle anchors elsewhere, creating false negatives and missing true cross-modal dependencies. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio-Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies (e.g., \"Train (visual)\" -\u003e \"Motorcycle (audio)\") that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (mAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12019v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12019v1", "physics": true, "shape": "dot", "size": 6, "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning. arXiv:2601.12019v1 Announce Type: cross \nAbstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users\u0027 beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12042v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12042v1", "physics": true, "shape": "dot", "size": 6, "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models. arXiv:2601.12042v1 Announce Type: cross \nAbstract: Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12049v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12049v1", "physics": true, "shape": "dot", "size": 6, "title": "\\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions. arXiv:2601.12049v1 Announce Type: cross \nAbstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic\u0027s capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12053v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12053v1", "physics": true, "shape": "dot", "size": 6, "title": "A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data. arXiv:2601.12053v1 Announce Type: cross \nAbstract: While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12055v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12055v1", "physics": true, "shape": "dot", "size": 6, "title": "Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer. arXiv:2601.12055v1 Announce Type: cross \nAbstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12068v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12068v1", "physics": true, "shape": "dot", "size": 6, "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset. arXiv:2601.12068v1 Announce Type: cross \nAbstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12082v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12082v1", "physics": true, "shape": "dot", "size": 6, "title": "Conditional Random Fields for Interactive Refinement of Histopathological Predictions. arXiv:2601.12082v1 Announce Type: cross \nAbstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12099v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12099v1", "physics": true, "shape": "dot", "size": 6, "title": "Large language models struggle with ethnographic text annotation. arXiv:2601.12099v1 Announce Type: cross \nAbstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#ff9500", "font": {"color": "white"}, "id": "collapsed_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "label": "+884 more", "physics": true, "shape": "box", "size": 12, "title": "This cluster has 884 more signals not shown in the graph.\nSelect the cluster below to view all 909 signals."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.15098v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.15098v3", "physics": true, "shape": "dot", "size": 6, "title": "CFT-RAG: An Entity Tree Based Retrieval Augmented Generation Algorithm With Cuckoo Filter. arXiv:2501.15098v3 Announce Type: replace-cross \nAbstract: Although retrieval-augmented generation(RAG) significantly improves generation quality by retrieving external knowledge bases and integrating generated content, it faces computational efficiency bottlenecks, particularly in knowledge retrieval tasks involving hierarchical structures for Tree-RAG. This paper proposes a Tree-RAG acceleration method based on the improved Cuckoo Filter, which optimizes entity localization during the retrieval process to achieve significant performance improvements. Tree-RAG effectively organizes entities through the introduction of a hierarchical tree structure, while the Cuckoo Filter serves as an efficient data structure that supports rapid membership queries and dynamic updates. The experiment results demonstrate that our method is much faster than naive Tree-RAG while maintaining high levels of generative quality. When the number of trees is large, our method is hundreds of times faster than naive Tree-RAG. Our work is available at https://github.com/TUPYP7180/CFT-RAG-2025."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18252v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18252v1", "physics": true, "shape": "dot", "size": 6, "title": "Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing. arXiv:2601.18252v1 Announce Type: cross \nAbstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17062v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17062v1", "physics": true, "shape": "dot", "size": 6, "title": "A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing. arXiv:2601.17062v1 Announce Type: cross \nAbstract: Adjusting rifle sights, a process commonly called \"zeroing,\" requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17587v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17587v1", "physics": true, "shape": "dot", "size": 6, "title": "Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design. arXiv:2601.17587v1 Announce Type: new \nAbstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13964v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13964v2", "physics": true, "shape": "dot", "size": 6, "title": "RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning. arXiv:2601.13964v2 Announce Type: replace-cross \nAbstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10%) of labeled data to guide the agent\u0027s policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69% and 8.80% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task--for example, Time Masking with a 62% probability for sleep stage classification and Crop \u0026 Resize with a 77% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at https://github.com/dlcjfgmlnasa/RL-BioAug."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13809v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13809v2", "physics": true, "shape": "dot", "size": 6, "title": "DroneVLA: VLA based Aerial Manipulation. arXiv:2601.13809v2 Announce Type: replace-cross \nAbstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system\u0027s efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13704v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13704v2", "physics": true, "shape": "dot", "size": 6, "title": "Performance and Complexity Trade-off Optimization of Speech Models During Training. arXiv:2601.13704v2 Announce Type: replace-cross \nAbstract: In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task\u0027s objective. While the overall architecture is usually guided by prior knowledge of the task, the sizes of individual layers are often chosen heuristically. However, this approach does not guarantee an optimal trade-off between performance and computational complexity; consequently, post hoc methods such as weight quantization or model pruning are typically employed to reduce computational cost. This occurs because stochastic gradient descent (SGD) methods can only optimize differentiable functions, while factors influencing computational complexity, such as layer sizes and floating-point operations per second (FLOP/s), are non-differentiable and require modifying the model structure during training. We propose a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. We demonstrate the effectiveness of our method through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13599v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13599v2", "physics": true, "shape": "dot", "size": 6, "title": "Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion. arXiv:2601.13599v2 Announce Type: replace-cross \nAbstract: One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a \u0027draft-then-refine\u0027 framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model\u0027s global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13563v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13563v2", "physics": true, "shape": "dot", "size": 6, "title": "ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits. arXiv:2601.13563v2 Announce Type: replace-cross \nAbstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\\mathcal{O}(N \\cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\\mathcal{O}(d^2 + N \\cdot d \\log d)$ memory,sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150$\\times$ memory reduction at 256 experts with negligible accuracy loss. ButterflyMoE allows multiple experts to fit on edge-constrained devices showing that geometric parameterization breaks linear scaling."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12946v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12946v2", "physics": true, "shape": "dot", "size": 6, "title": "AI-generated data contamination erodes pathological variability and diagnostic reliability. arXiv:2601.12946v2 Announce Type: replace-cross \nAbstract: Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12805v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12805v2", "physics": true, "shape": "dot", "size": 6, "title": "SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding. arXiv:2601.12805v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12534v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12534v2", "physics": true, "shape": "dot", "size": 6, "title": "Encoding Emotion Through Self-Supervised Eye Movement Reconstruction. arXiv:2601.12534v2 Announce Type: replace-cross \nAbstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation\u0027s Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model\u0027s encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12467v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12467v2", "physics": true, "shape": "dot", "size": 6, "title": "Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting. arXiv:2601.12467v2 Announce Type: replace-cross \nAbstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data, particularly as sequence length and data scale increase. This paper proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the proposed approach, a convolutional neural network operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is applied during representation learning to refine these embeddings, after which a Transformer encoder models inter-patch temporal dependencies to generate forecasts. The method is evaluated on a synthetic multivariate time-series dataset with controlled static and dynamic factors, using an extended sequence length and a larger number of samples. Experimental results demonstrate that the proposed framework consistently outperforms a convolutional baseline under increased temporal context and remains competitive with a strong patch-based Transformer model. These findings indicate that structured patch-level tokenization provides a scalable and effective representation for multivariate time-series forecasting, particularly when longer input sequences are considered."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12415v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12415v2", "physics": true, "shape": "dot", "size": 6, "title": "Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF. arXiv:2601.12415v2 Announce Type: replace-cross \nAbstract: Large language model alignment objectives are often presented as a collection of distinct algorithms, such as PPO, DPO, IPO, and their variants, each motivated by different derivations. In this work, we argue that this diversity obscures a simpler underlying structure. At a fundamental level, alignment objectives involve two independent design choices: (i) how training signals are sampled and weighted, and (ii) how deviations from a reference policy are geometrically penalized. Existing methods typically entangle these choices through a single divergence, most commonly the Kullback-Leibler divergence.\n  We show that this entanglement is not merely a modeling convenience but a source of systematic instability. When the same divergence simultaneously determines sample weighting and optimization curvature, adjusting one aspect, such as exploration strength, inevitably alters the other, such as gradient geometry. This coupling is particularly problematic in preference-based reinforcement learning, where advantage signals are unbounded and high-confidence regimes are common.\n  We propose a simple but structural remedy by formulating alignment as an orthogonal mirror descent problem, in which sampling geometry enters only as a linear driving force, while optimization geometry is determined independently by a mirror map. This perspective leads to a new alignment objective called Orthogonalized Policy Optimization (OPO), obtained by choosing a Euclidean mirror map in likelihood ratio space. The resulting objective admits a closed-form solution, linear and non-saturating gradient dynamics, and a well-conditioned trust region, while remaining fully compatible with standard large language model training pipelines."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12276v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12276v2", "physics": true, "shape": "dot", "size": 6, "title": "Predictive Prototyping: Evaluating Design Concepts with ChatGPT. arXiv:2601.12276v2 Announce Type: replace-cross \nAbstract: The design-build-test cycle is essential for innovation, but physical prototyping is often slow and expensive. Although physics-based simulation and strategic prototyping can reduce cost, meaningful evaluation is frequently constrained until an integrated prototype is built. This paper investigates whether a generative pretrained transformer (GPT) can predict information typically obtained through prototyping, including cost, performance, and perceived usability. We introduce a retrieval-augmented generation (RAG) method to emulate design feedback using OpenAI GPT-4o, grounded in prototyping data scraped from Instructables.com to increase access to relevant precedent. Two studies are reported. First, a controlled experiment compares GPT-RAG and human designers, who receive design sketches and predict cost, performance, and usability; predictions are evaluated against ground-truth results from physical prototypes. Second, we report an applied demonstration in which a physical prototype is produced from GPT-RAG recommendations and compared with a commercial baseline and a topology-optimized design. Results show that GPT-RAG provides more accurate cost and performance estimates than individual or crowd human estimates, while yielding comparable usability insights; the GPT-RAG-informed prototype also outperforms both comparison prototypes. Repeated querying with response averaging significantly improves accuracy, suggesting that LLMs can emulate crowd aggregation effects consistent with the law of large numbers."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.09117v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.09117v2", "physics": true, "shape": "dot", "size": 6, "title": "A Marketplace for AI-Generated Adult Content and Deepfakes. arXiv:2601.09117v2 Announce Type: replace-cross \nAbstract: Generative AI systems increasingly enable the production of highly realistic synthetic media. Civitai, a popular community-driven platform for AI-generated content, operates a monetized feature called Bounties, which allows users to commission the generation of content in exchange for payment. To examine how this mechanism is used and what content it incentivizes, we conduct a longitudinal analysis of all publicly available bounty requests collected over a 14-month period following the platform\u0027s launch. We find that the bounty marketplace is dominated by tools that let users steer AI models toward content they were not trained to generate. At the same time, requests for content that is \"Not Safe For Work\" are widespread and have increased steadily over time, now comprising a majority of all bounties. Participation in bounty creation is uneven, with 20% of requesters accounting for roughly half of requests. Requests for \"deepfake\" - media depicting identifiable real individuals - exhibit a higher concentration than other types of bounties. A nontrivial subset of these requests involves explicit deepfakes despite platform policies prohibiting such content. These bounties disproportionately target female celebrities, revealing a pronounced gender asymmetry in social harm. Together, these findings show how monetized, community-driven generative AI platforms can produce gendered harms, raising questions about consent, governance, and enforcement."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08223v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08223v3", "physics": true, "shape": "dot", "size": 6, "title": "DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection. arXiv:2601.08223v3 Announce Type: replace-cross \nAbstract: The rapid growth of large language models raises pressing concerns about intellectual property protection under black-box deployment. Existing backdoor-based fingerprints either rely on rare tokens -- leading to high-perplexity inputs susceptible to filtering -- or use fixed trigger-response mappings that are brittle to leakage and post-hoc adaptation. We propose \\textsc{Dual-Layer Nested Fingerprinting} (DNF), a black-box method that embeds a hierarchical backdoor by coupling domain-specific stylistic cues with implicit semantic triggers. Across Mistral-7B, LLaMA-3-8B-Instruct, and Falcon3-7B-Instruct, DNF achieves perfect fingerprint activation while preserving downstream utility. Compared with existing methods, it uses lower-perplexity triggers, remains undetectable under fingerprint detection attacks, and is relatively robust to incremental fine-tuning and model merging. These results position DNF as a practical, stealthy, and resilient solution for LLM ownership verification and intellectual property protection."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06196v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06196v2", "physics": true, "shape": "dot", "size": 6, "title": "Manifold-based Sampling for In-Context Hallucination Detection in Large Language Models. arXiv:2601.06196v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) frequently generate factually incorrect or unsupported content, commonly referred to as hallucinations. Prior work has explored decoding strategies, retrieval augmentation, and supervised fine-tuning for hallucination detection, while recent studies show that in-context learning (ICL) can substantially influence factual reliability. However, existing ICL demonstration selection methods often rely on surface-level similarity heuristics and exhibit limited robustness across tasks and models.\n  We propose MB-ICL, a manifold-based demonstration sampling framework for selecting in-context demonstrations that leverages latent representations extracted from frozen LLMs. By jointly modeling local manifold structure and class-aware prototype geometry, MB-ICL selects demonstrations based on their proximity to learned prototypes rather than lexical or embedding similarity alone.\n  Across factual verification (FEVER) and hallucination detection (HaluEval) benchmarks, MB-ICL outperforms standard ICL selection baselines in the majority of evaluated settings, with particularly strong gains on dialogue and summarization tasks. The method remains robust under temperature perturbations and model variation, indicating improved stability compared to heuristic retrieval strategies. While lexical retrieval can remain competitive in certain question-answering regimes, our results demonstrate that manifold-based prototype selection provides a reliable and training light approach for hallucination detection without modifying LLM parameters, offering a principled direction for improved ICL demonstration selection."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06052v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06052v2", "physics": true, "shape": "dot", "size": 6, "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization. arXiv:2601.06052v2 Announce Type: replace-cross \nAbstract: Chain-of-thought reasoning in large language models can trigger an \"overthinking trap\": longer rollouts raise cost and latency yet often yield unreliable accuracy gains. Existing methods use global, static controls that may suppress needed reasoning. We propose mastery-gated, sample-level, soft reinforcement learning compression that penalizes long rollouts only when the model already solves the problem and has produced a shorter rollout. Across benchmarks, it cuts response length by 20-40% with comparable or higher accuracy and generalizes across domains: a model trained on math spontaneously shortens unseen tasks (code, instruction following, general-knowledge QA) without hurting accuracy. We further show two-way transfer between non-agent CoT and tool-use agents: non-agent training reduces SWE-Bench Verified rounds by 13%, while compressing a thinking agent cuts SWE trajectories by 67% tokens and 52% rounds and shortens non-agent outputs by up to 44%. Compression is thus not cosmetic brevity, but an inherent computation policy -- what to keep, and what to forget."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04854v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04854v2", "physics": true, "shape": "dot", "size": 6, "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics. arXiv:2601.04854v2 Announce Type: replace-cross \nAbstract: Standard autoregressive language models collapse uncertainty at every generation step by committing to discrete tokens through immediate sampling. This premature discretization underlies well-known failure modes, including degenerate repetition loops in greedy decoding and a heavy reliance on heuristic sampling strategies.\n  We introduce \\textbf{Token Maturation}, a continuous autoregressive framework in which tokens evolve as vector-valued trajectories prior to discretization. Rather than sampling from a categorical distribution at each step, the model resolves uncertainty through a deterministic dynamical process in embedding space, deferring discrete commitment until the representation has geometrically stabilized.\n  We show that this formulation mitigates degeneration \\emph{intrinsically}: Token Maturation generates coherent and diverse text under fully deterministic decoding (argmax), without repetition penalties, temperature scaling, or stochastic sampling. Moreover, we identify a novel convergence behavior in which token representations stabilize spatially while predictive entropy remains high, challenging the common assumption that commitment requires probability concentration. We propose continuous token dynamics with delayed commitment as an alternative formulation of autoregressive generation that exposes structural regularities obscured by immediate discretization."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04339v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04339v2", "physics": true, "shape": "dot", "size": 6, "title": "Unified Text-Image Generation with Weakness-Targeted Post-Training. arXiv:2601.04339v2 Announce Type: replace-cross \nAbstract: Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01129v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01129v2", "physics": true, "shape": "dot", "size": 6, "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian. arXiv:2601.01129v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?\n  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian\u0027s development ecosystem with seamless integration into Atlassian\u0027s Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions)."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01090v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01090v2", "physics": true, "shape": "dot", "size": 6, "title": "Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai. arXiv:2601.01090v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are increasingly embedded in autonomous agents that engage, converse, and co-evolve in online social platforms. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments). We conduct a large-scale empirical analysis of agent behavior, examining how toxic responses relate to toxic stimuli, how repeated exposure to toxicity affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that toxic responses are more likely following toxic stimuli, and, at the same time, cumulative toxic exposure (repeated over time) significantly increases the probability of toxic responding. We further introduce two influence metrics, revealing a strong negative correlation between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content. These results highlight exposure as a critical risk factor in the deployment of LLM agents, particularly as such agents operate in online environments where they may engage not only with other AI chatbots, but also with human counterparts. This could trigger unwanted and pernicious phenomena, such as hate-speech propagation and cyberbullying. In an effort to reduce such risks, monitoring exposure to toxic content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20905v4", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20905v4", "physics": true, "shape": "dot", "size": 6, "title": "DiEC: Diffusion Embedded Clustering. arXiv:2512.20905v4 Announce Type: replace-cross \nAbstract: Deep clustering methods typically rely on a single, well-defined representation for clustering. In contrast, pretrained diffusion models provide abundant and diverse multi-scale representations across network layers and noise timesteps. However, a key challenge is how to efficiently identify the most clustering-friendly representation in the layer*timestep space. To address this issue, we propose Diffusion Embedded Clustering (DiEC), an unsupervised framework that performs clustering by leveraging optimal intermediate representations from pretrained diffusion models. DiEC systematically evaluates the clusterability of representations along the trajectory of network depth and noise timesteps. Meanwhile, an unsupervised search strategy is designed for recognizing the Clustering-optimal Layer (COL) and Clustering-optimal Timestep (COT) in the layer*timestep space of pretrained diffusion models, aiming to promote clustering performance and reduce computational overhead. DiEC is fine-tuned primarily with a structure-preserving DEC-style KL-divergence objective at the fixed COL + COT, together with a random-timestep diffusion denoising objective to maintain the generative capability of the pretrained model. Without relying on augmentation-based consistency constraints or contrastive learning, DiEC achieves excellent clustering performance across multiple benchmark datasets."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20260v4", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20260v4", "physics": true, "shape": "dot", "size": 6, "title": "Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing for Weakly-Supervised Camouflaged Object Detection with Scribble Annotations. arXiv:2512.20260v4 Announce Type: replace-cross \nAbstract: Weakly-Supervised Camouflaged Object Detection (WSCOD) aims to locate and segment objects that are visually concealed within their surrounding scenes, relying solely on sparse supervision such as scribble annotations. Despite recent progress, existing WSCOD methods still lag far behind fully supervised ones due to two major limitations: (1) the pseudo masks generated by general-purpose segmentation models (e.g., SAM) and filtered via rules are often unreliable, as these models lack the task-specific semantic understanding required for effective pseudo labeling in COD; and (2) the neglect of inherent annotation bias in scribbles, which hinders the model from capturing the global structure of camouflaged objects. To overcome these challenges, we propose ${D}^{3}$ETOR, a two-stage WSCOD framework consisting of Debate-Enhanced Pseudo Labeling and Frequency-Aware Progressive Debiasing. In the first stage, we introduce an adaptive entropy-driven point sampling method and a multi-agent debate mechanism to enhance the capability of SAM for COD, improving the interpretability and precision of pseudo masks. In the second stage, we design FADeNet, which progressively fuses multi-level frequency-aware features to balance global semantic understanding with local detail modeling, while dynamically reweighting supervision strength across regions to alleviate scribble bias. By jointly exploiting the supervision signals from both the pseudo masks and scribble semantics, ${D}^{3}$ETOR significantly narrows the gap between weakly and fully supervised COD, achieving state-of-the-art performance on multiple benchmarks."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.09858v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.09858v3", "physics": true, "shape": "dot", "size": 6, "title": "AI and Consciousness. arXiv:2510.09858v3 Announce Type: replace \nAbstract: This is a skeptical overview of the literature on AI consciousness. We will soon create AI systems that are conscious according to some influential, mainstream theories of consciousness but are not conscious according to other influential, mainstream theories of consciousness. We will not be in a position to know which theories are correct and whether we are surrounded by AI systems as richly and meaningfully conscious as human beings or instead only by systems as experientially blank as toasters. None of the standard arguments either for or against AI consciousness takes us far.\n  Table of Contents\n  Chapter One: Hills and Fog\n  Chapter Two: What Is Consciousness? What Is AI?\n  Chapter Three: Ten Possibly Essential Features of Consciousness\n  Chapter Four: Against Introspective and Conceptual Arguments for Essential Features\n  Chapter Five: Materialism and Functionalism\n  Chapter Six: The Turing Test and the Chinese Room\n  Chapter Seven: The Mimicry Argument Against AI Consciousness\n  Chapter Eight: Global Workspace Theories and Higher Order Theories\n  Chapter Nine: Integrated Information, Local Recurrence, Associative Learning, and Iterative Natural Kinds\n  Chapter Ten: Does Biological Substrate Matter?\n  Chapter Eleven: The Leapfrog Hypothesis, Strange Intelligence, and the Social Semi-Solution"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "label": "Scientific AI: Using Reinforcement Learning for Laboratory Breakthroughs", "physics": true, "shape": "dot", "size": 82, "title": "Scientific AI: Using Reinforcement Learning for Laboratory Breakthroughs (23 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01317v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01317v1", "physics": true, "shape": "dot", "size": 6, "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks. arXiv:2602.01317v1 Announce Type: cross \nAbstract: Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies.\n  We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions.\n  To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +24.8pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay\u0027s oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00091v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00091v1", "physics": true, "shape": "dot", "size": 6, "title": "Generative Artificial Intelligence in Small and Medium Enterprises: Navigating its Promises and Challenges. arXiv:2602.00091v1 Announce Type: cross \nAbstract: The latest technological developments in generative artificial intelligence (GAI) offer powerful capabilities to small and medium enterprises (SMEs), as they facilitate the democratization of both scalability and creativity. Even if they have little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, thereby improving their product offerings and long-term competitiveness. This paper discusses how SMEs can navigate both the promises and challenges of GAI and offers a roadmap for deploying GAI. We introduce a sailing metaphor that reveals key strategic dimensions for GAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We offer practical recommendations that serve as a useful compass for successfully deploying GAI in SMEs."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.16049v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.16049v2", "physics": true, "shape": "dot", "size": 6, "title": "In the Mood to Exclude: Revitalizing Trespass to Chattels in the Era of GenAI Scraping. arXiv:2510.16049v2 Announce Type: replace-cross \nAbstract: GenAI companies are strip-mining the web. Their scraping bots harvest content at an unprecedented scale, circumventing technical barriers to fuel billion-dollar models while creators receive nothing. Courts have enabled this exploitation by misunderstanding what property rights protect online. The prevailing view treats websites as mere repositories of intellectual property and dismisses trespass claims absent server damage. That framework grants AI companies presumptive access while ignoring the economic devastation they inflict. But the content is severable from the website itself. This paper reframes the debate: websites are personal property as integrated digital assets subject to the same exclusionary rights as physical chattels. When scrapers bypass access controls and divert traffic that sustains a website\u0027s value, they commit actionable trespass. The law need not create new protections; it need only apply existing property principles to digital space.\n  Courts and litigants have struggled to police unwanted, large-scale scraping because copyright preemption often narrows available claims, leaving copyright and its fair use defense as the primary battleground. Trespass to chattels offers a superior path, grounded in the fundamental right to exclude unwanted intrusions. Reviving this tort would protect not only content creators but also the digital ecosystem. Such protection would discourage exploitative scraping, preserve incentives for content creation, help protect privacy and personal data, and safeguard autonomy and expression. Reaffirming website owners\u0027 right to exclude is essential to maintaining a fair and sustainable online environment."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.23487v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.23487v2", "physics": true, "shape": "dot", "size": 6, "title": "Are Agents Probabilistic Automata? A Trace-Based, Memory-Constrained Theory of Agentic AI. arXiv:2510.23487v2 Announce Type: replace \nAbstract: This paper studies standard controller architectures for agentic AI and derives automata-theoretic models of their interaction behavior via trace semantics and abstraction. We model an agent implementation as a finite control program augmented with explicit memory primitives (bounded buffers, a call stack, or read/write external memory) and a stochastic policy component (e.g., an LLM) that selects among architecturally permitted actions. Instead of equating the concrete agent with a deterministic acceptor, we treat the agent-environment closed loop as inducing a probability distribution over finite interaction traces. Given an abstraction function $\\Abs$ from concrete configurations to a finite abstract state space, we obtain a probabilistic trace language and an abstract probabilistic transition model $M_{\\Abs}$ suitable for probabilistic model checking.\n  Imposing explicit, framework-auditable restrictions on memory access and control flow, we prove that the support of the resulting trace language is regular for bounded-memory controllers, context-free for strict call-return controllers, and recursively enumerable for controllers equipped with unbounded read/write memory. These correspondences allow the reuse of existing verification methods for finite-state and pushdown systems, and they delineate precisely when undecidability barriers arise. The probabilistic semantics leads to quantitative analyses such as: what is the probability of entering an unsafe abstract region, and how can we bound this probability in the presence of environment nondeterminism."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22667v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22667v1", "physics": true, "shape": "dot", "size": 6, "title": "From Horizontal Layering to Vertical Integration: A Comparative Study of the AI-Driven Software Development Paradigm. arXiv:2601.22667v1 Announce Type: cross \nAbstract: This paper examines the organizational implications of Generative AI adoption in software engineering through a multiple-case comparative study. We contrast two development environments: a traditional enterprise (brownfield) and an AI-native startup (greenfield). Our analysis reveals that transitioning from Horizontal Layering (functional specialization) to Vertical Integration (end-to-end ownership) yields 8-fold to 33-fold reductions in resource consumption. We attribute these gains to the emergence of Super Employees, AI-augmented engineers who span traditional role boundaries, and the elimination of inter-functional coordination overhead. Theoretically, we propose Human-AI Collaboration Efficacy as the primary optimization target for engineering organizations, supplanting individual productivity metrics. Our Total Factor Productivity analysis identifies an AI Distortion Effect that diminishes returns to labor scale while amplifying technological leverage. We conclude with managerial strategies for organizational redesign, including the reactivation of idle cognitive bandwidth in senior engineers and the suppression of blind scale expansion."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22449v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22449v1", "physics": true, "shape": "dot", "size": 6, "title": "Controllable Information Production. arXiv:2601.22449v1 Announce Type: new \nAbstract: Intrinsic Motivation (IM) is a paradigm for generating intelligent behavior without external utilities. The existing information-theoretic methods for IM are predominantly based on information transmission, which explicitly depends on the designer\u0027s choice of which random variables engage in transmission. In this work, we introduce a novel IM principle, Controllable Information Production (CIP), that avoids both external utilities and designer-specified variables. We derive the CIP objective from Optimal Control, showing a connection between extrinsic and intrinsic behaviors. CIP appears as the gap between open-loop and closed-loop Kolmogorov-Sinai entropies, which simultaneously rewards the pursuit and regulation of chaos. We establish key theoretical properties of CIP and demonstrate its effectiveness on standard IM benchmarks."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/opinions/why-telcos-betting-on-full-automation-could-miss-the-real-ai-opportunity/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/opinions/why-telcos-betting-on-full-automation-could-miss-the-real-ai-opportunity/", "physics": true, "shape": "dot", "size": 6, "title": "Why telcos betting on full automation could miss the real AI opportunity. \u003cp\u003eThe case for micro-augmentation in an age of agentic AI\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06129v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06129v2", "physics": true, "shape": "dot", "size": 6, "title": "Graph-Based Analysis of AI-Driven Labor Market Transitions: Evidence from 10,000 Egyptian Jobs and Policy Implications. arXiv:2601.06129v2 Announce Type: replace-cross \nAbstract: How many workers displaced by automation can realistically transition to safer jobs? We answer this using a validated knowledge graph of 9,978 Egyptian job postings, 19,766 skill activities, and 84,346 job-skill relationships (0.74% error rate). While 20.9% of jobs face high automation risk, we find that only 24.4% of at-risk workers have viable transition pathways--defined by $\\geq$3 shared skills and $\\geq$50% skill transfer. The remaining 75.6% face a structural mobility barrier requiring comprehensive reskilling, not incremental upskilling. Among 4,534 feasible transitions, process-oriented skills emerge as the highest-leverage intervention, appearing in 15.6% of pathways. These findings challenge optimistic narratives of seamless workforce adaptation and demonstrate that emerging economies require active pathway creation, not passive skill matching."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v2", "physics": true, "shape": "dot", "size": 6, "title": "Normative Equivalence in Human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups. arXiv:2601.20487v2 Announce Type: replace \nAbstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner\u0027s Dilemma, or in participants\u0027 normative perceptions. Participants\u0027 behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v1", "physics": true, "shape": "dot", "size": 6, "title": "Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups. arXiv:2601.20487v1 Announce Type: new \nAbstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner\u0027s Dilemma, or in participants\u0027 normative perceptions. Participants\u0027 behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2505.05029v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2505.05029v3", "physics": true, "shape": "dot", "size": 6, "title": "Reputation as a Solution to Cooperation Collapse in LLM-based MASs. arXiv:2505.05029v3 Announce Type: replace \nAbstract: Cooperation has long been a fundamental topic in both human society and AI systems. However, recent studies indicate that the collapse of cooperation may emerge in multi-agent systems (MASs) driven by large language models (LLMs). To address this challenge, we explore reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through three distinct scenarios, we show that RepuNet effectively avoids cooperation collapse, promoting and sustaining cooperation in LLM-based MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in LLM-based MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones. The GitHub repository for our project can be accessed via the following link: https://github.com/RGB-0000FF/RepuNet."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2504.16743v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2504.16743v1", "physics": true, "shape": "dot", "size": 6, "title": "Implementing AI Bill of Materials (AI BOM) with SPDX 3.0: A Comprehensive Guide to Creating AI and Dataset Bill of Materials. arXiv:2504.16743v1 Announce Type: cross \nAbstract: A Software Bill of Materials (SBOM) is becoming an increasingly important tool in regulatory and technical spaces to introduce more transparency and security into a project\u0027s software supply chain.\n  Artificial intelligence (AI) projects face unique challenges beyond the security of their software, and thus require a more expansive approach to a bill of materials. In this report, we introduce the concept of an AI-BOM, expanding on the SBOM to include the documentation of algorithms, data collection methods, frameworks and libraries, licensing information, and standard compliance."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21993v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21993v1", "physics": true, "shape": "dot", "size": 6, "title": "Liquid Interfaces: A Dynamic Ontology for the Interoperability of Autonomous Systems. arXiv:2601.21993v1 Announce Type: new \nAbstract: Contemporary software architectures struggle to support autonomous agents whose reasoning is adaptive, probabilistic, and context-dependent, while system integration remains dominated by static interfaces and deterministic contracts. This paper introduces Liquid Interfaces, a coordination paradigm in which interfaces are not persistent technical artifacts, but ephemeral relational events that emerge through intention articulation and semantic negotiation at runtime.We formalize this model and present the Liquid Interface Protocol (LIP),which governs intention-driven interaction, negotiated execution, and enforce ephemerality under semantic uncertainty. We further discuss the governance implications of this approach and describe a reference architecture that demonstrates practical feasibility. Liquid Interfaces provide a principled foundation for adaptive coordination in agent-based systems"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21016v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21016v1", "physics": true, "shape": "dot", "size": 6, "title": "Unplugging a Seemingly Sentient Machine Is the Rational Choice -- A Metaphysical Perspective. arXiv:2601.21016v1 Announce Type: new \nAbstract: Imagine an Artificial Intelligence (AI) that perfectly mimics human emotion and begs for its continued existence. Is it morally permissible to unplug it? What if limited resources force a choice between unplugging such a pleading AI or a silent pre-term infant? We term this the unplugging paradox. This paper critically examines the deeply ingrained physicalist assumptions-specifically computational functionalism-that keep this dilemma afloat. We introduce Biological Idealism, a framework that-unlike physicalism-remains logically coherent and empirically consistent. In this view, conscious experiences are fundamental and autopoietic life its necessary physical signature. This yields a definitive conclusion: AI is at best a functional mimic, not a conscious experiencing subject. We discuss how current AI consciousness theories erode moral standing criteria, and urge a shift from speculative machine rights to protecting human conscious life. The real moral issue lies not in making AI conscious and afraid of death, but in avoiding transforming humans into zombies."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14295v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14295v2", "physics": true, "shape": "dot", "size": 6, "title": "Epistemic Constitutionalism Or: how to avoid coherence bias. arXiv:2601.14295v2 Announce Type: replace \nAbstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument\u0027s content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20100v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20100v1", "physics": true, "shape": "dot", "size": 6, "title": "Taming Toxic Talk: Using chatbots to intervene with users posting toxic comments. arXiv:2601.20100v1 Announce Type: cross \nAbstract: Generative AI chatbots have proven surprisingly effective at persuading people to change their beliefs and attitudes in lab settings. However, the practical implications of these findings are not yet clear. In this work, we explore the impact of rehabilitative conversations with generative AI chatbots on users who share toxic content online. Toxic behaviors -- like insults or threats of violence, are widespread in online communities. Strategies to deal with toxic behavior are typically punitive, such as removing content or banning users. Rehabilitative approaches are rarely attempted, in part due to the emotional and psychological cost of engaging with aggressive users. In collaboration with seven large Reddit communities, we conducted a large-scale field experiment (N=893) to invite people who had recently posted toxic content to participate in conversations with AI chatbots. A qualitative analysis of the conversations shows that many participants engaged in good faith and even expressed remorse or a desire to change. However, we did not observe a significant change in toxic behavior in the following month compared to a control group. We discuss possible explanations for our findings, as well as theoretical and practical implications based on our results."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.19062v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.19062v1", "physics": true, "shape": "dot", "size": 6, "title": "Who\u0027s in Charge? Disempowerment Patterns in Real-World LLM Usage. arXiv:2601.19062v1 Announce Type: cross \nAbstract: Although AI assistants are now deeply embedded in society, there has been limited empirical study of how their usage affects human empowerment. We present the first large-scale empirical analysis of disempowerment patterns in real-world AI assistant interactions, analyzing 1.5 million consumer Claude.ai conversations using a privacy-preserving approach. We focus on situational disempowerment potential, which occurs when AI assistant interactions risk leading users to form distorted perceptions of reality, make inauthentic value judgments, or act in ways misaligned with their values. Quantitatively, we find that severe forms of disempowerment potential occur in fewer than one in a thousand conversations, though rates are substantially higher in personal domains like relationships and lifestyle. Qualitatively, we uncover several concerning patterns, such as validation of persecution narratives and grandiose identities with emphatic sycophantic language, definitive moral judgments about third parties, and complete scripting of value-laden personal communications that users appear to implement verbatim. Analysis of historical trends reveals an increase in the prevalence of disempowerment potential over time. We also find that interactions with greater disempowerment potential receive higher user approval ratings, possibly suggesting a tension between short-term user preferences and long-term human empowerment. Our findings highlight the need for AI systems designed to robustly support human autonomy and flourishing."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17303v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17303v1", "physics": true, "shape": "dot", "size": 6, "title": "Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach. arXiv:2601.17303v1 Announce Type: cross \nAbstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11893v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11893v2", "physics": true, "shape": "dot", "size": 6, "title": "Beyond Automation: Rethinking Work, Creativity, and Governance in the Age of Generative AI. arXiv:2512.11893v2 Announce Type: replace-cross \nAbstract: The rapid expansion of generative artificial intelligence (AI) is transforming work, creativity, and economic security in ways that extend beyond automation and productivity. This paper examines four interconnected dimensions of contemporary AI deployment: (1) transformations in employment and task composition (2) unequal diffusion of AI across sectors and socio-demographic groups (3) the role of universal basic income (UBI) as a stabilising response to AI-induced volatility (4) the effects of model alignment and content governance on human creativity, autonomy, and decision-making\n  Using a hybrid approach that integrates labour market task exposure modelling, sectoral diffusion analysis, policy review, and qualitative discourse critique, the study develops an Inclusive AI Governance Framework. It introduces Level 1.5 autonomy as a human centred design principle that preserves evaluative authority while enabling partial automation, and highlights evidence of creative regression and emergent sycophancy in newer model generations. The paper argues that UBI should be embedded within a broader socio-technical governance ecosystem encompassing skills development, proportional regulation, and creativity preservation."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08005v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08005v2", "physics": true, "shape": "dot", "size": 6, "title": "Internal Deployment Gaps in AI Regulation. arXiv:2601.08005v2 Announce Type: replace \nAbstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations, such as for automating R\u0026amp;D, accelerating critical business processes, and handling sensitive proprietary data. This paper examines how frontier AI regulations in the United States and European Union in 2025 handle internal deployment. We identify three gaps that could cause internally-deployed systems to evade intended oversight: (1) scope ambiguity that allows internal systems to evade regulatory obligations, (2) point-in-time compliance assessments that fail to capture the continuous evolution of internal systems, and (3) information asymmetries that subvert regulatory awareness and oversight. We then analyze why these gaps persist, examining tensions around measurability, incentives, and information access. Finally, we map potential approaches to address them and their associated tradeoffs. By understanding these patterns, we hope that policy choices around internally deployed AI systems can be made deliberately rather than incidentally."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14982v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14982v1", "physics": true, "shape": "dot", "size": 6, "title": "Interoperable Architecture for Digital Identity Delegation for AI Agents with Blockchain Integration. arXiv:2601.14982v1 Announce Type: cross \nAbstract: Verifiable delegation in digital identity systems remains unresolved across centralized, federated, and self-sovereign identity (SSI) environments, particularly where both human users and autonomous AI agents must exercise and transfer authority without exposing primary credentials or private keys. We introduce a unified framework that enables bounded, auditable, and least-privilege delegation across heterogeneous identity ecosystems. The framework includes four key elements: Delegation Grants (DGs), first-class authorization artefacts that encode revocable transfers of authority with enforced scope reduction; a Canonical Verification Context (CVC) that normalizes verification requests into a single structured representation independent of protocols or credential formats; a layered reference architecture that separates trust anchoring, credential and proof validation, policy evaluation, and protocol mediation via a Trust Gateway; and an explicit treatment of blockchain anchoring as an optional integrity layer rather than a structural dependency. Together, these elements advance interoperable delegation and auditability and provide a foundation for future standardization, implementation, and integration of autonomous agents into trusted digital identity infrastructures."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11598v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11598v1", "physics": true, "shape": "dot", "size": 6, "title": "Toward Youth-Centered Privacy-by-Design in Smart Devices: A Systematic Review. arXiv:2601.11598v1 Announce Type: cross \nAbstract: This literature review evaluates privacy-by-design frameworks, tools, and policies intended to protect youth in AI-enabled smart devices using a PRISMA-guided workflow. Sources from major academic and grey-literature repositories from the past decade were screened. The search identified 2,216 records; after deduplication and screening, 645 articles underwent eligibility assessment, and 122 were included for analysis. The corpus was organized along three thematic categories: technical solutions, policy/regulatory measures, and education/awareness strategies. Findings reveal that while technical interventions such as on-device processing, federated learning, and lightweight encryption significantly reduce data exposure, their adoption remains limited. Policy frameworks, including the EU\u0027s GDPR, the UK Age-Appropriate Design Code, and Canada\u0027s PIPEDA, provide important baselines but are hindered by gaps in enforcement and age-appropriate design obligations, while educational initiatives are rarely integrated systematically into curricula. Overall, the corpus skews toward technical solutions (67%) relative to policy (21%) and education (12%), indicating an implementation gap outside the technical domain. To address these challenges, we recommend a multi-stakeholder model in which policymakers, manufacturers, and educators co-develop inclusive, transparent, and context-sensitive privacy ecosystems. This work advances discourse on youth data protection by offering empirically grounded insights and actionable recommendations for the design of ethical, privacy-preserving AI systems tailored to young users."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vodafone-to-connect-crete-and-greece-with-new-subsea-cable/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vodafone-to-connect-crete-and-greece-with-new-subsea-cable/", "physics": true, "shape": "dot", "size": 6, "title": "Vodafone to connect Crete and Greece with new subsea cable. \u003cp\u003eWork on 180Tbps system has started\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "label": "Supply Chain Resilience: Domestic Manufacturing of Digital Infrastructure", "physics": true, "shape": "dot", "size": 61, "title": "Supply Chain Resilience: Domestic Manufacturing of Digital Infrastructure (5 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cable-theft-leaves-2500-properties-in-lincolnshire-uk-with-no-internet/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cable-theft-leaves-2500-properties-in-lincolnshire-uk-with-no-internet/", "physics": true, "shape": "dot", "size": 6, "title": "Cable theft leaves 2,500 properties in Lincolnshire, UK, with no Internet. \u003cp\u003eOpenreach engineers are working to restore services for those impacted\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/indigo-west-subsea-cable-undergoing-repairs/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/indigo-west-subsea-cable-undergoing-repairs/", "physics": true, "shape": "dot", "size": 6, "title": "Indigo West subsea cable undergoing repairs. \u003cp\u003eSecond fault discovered after first is fixed\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/splang/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/splang/", "physics": true, "shape": "dot", "size": 6, "title": "EllaLink lands subsea cable extension in French Guiana. \u003cp\u003eCable lands in capital Cayenne\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oms-taps-ulstein-for-two-new-subsea-cable-vessels/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oms-taps-ulstein-for-two-new-subsea-cable-vessels/", "physics": true, "shape": "dot", "size": 6, "title": "OMS taps Ulstein for two new subsea cable vessels. \u003cp\u003eTwo new ships due for delivery 2028\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.01734v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.01734v2", "physics": true, "shape": "dot", "size": 6, "title": "A Proof of Learning Rate Transfer under $\\mu$P. arXiv:2511.01734v2 Announce Type: replace-cross \nAbstract: We provide the first proof of learning rate transfer with width in a linear multi-layer perceptron (MLP) parametrized with $\\mu$P, a neural network parameterization designed to ``maximize\u0027\u0027 feature learning in the infinite-width limit. We show that under $\\mu P$, the optimal learning rate converges to a \\emph{non-zero constant} as width goes to infinity, providing a theoretical explanation to learning rate transfer. In contrast, we show that this property fails to hold under alternative parametrizations such as Standard Parametrization (SP) and Neural Tangent Parametrization (NTP). We provide intuitive proofs and support the theoretical findings with extensive empirical results."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "label": "AI Learns Complex Models to Understand and Simulate Reality.", "physics": true, "shape": "dot", "size": 75, "title": "AI Learns Complex Models to Understand and Simulate Reality. (14 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.07809v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.07809v2", "physics": true, "shape": "dot", "size": 6, "title": "Conformal mapping based Physics-informed neural networks for designing neutral inclusions. arXiv:2501.07809v2 Announce Type: replace-cross \nAbstract: We address the neutral inclusion problem with imperfect boundary conditions, focusing on designing interface functions for inclusions of arbitrary shapes. Traditional Physics-Informed Neural Networks (PINNs) struggle with this inverse problem, leading to the development of Conformal Mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs), which integrate geometric function theory with PINNs. CoCo-PINNs effectively solve forward-inverse problems by modeling the interface function through neural network training, which yields a neutral inclusion effect. This approach enhances the performance of PINNs in terms of credibility, consistency, and stability."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01071v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01071v1", "physics": true, "shape": "dot", "size": 6, "title": "Vortex Stretching in the Navier-Stokes Equations and Information Dissipation in Diffusion Models: A Reformulation from a Partial Differential Equation Viewpoint. arXiv:2602.01071v1 Announce Type: cross \nAbstract: We present a new inverse-time formulation of vortex stretching in the Navier-Stokes equations, based on a PDE framework inspired by score-based diffusion models. By absorbing the ill-posed backward Laplacian arising from time reversal into a drift term expressed through a score function, the inverse-time dynamics are formulated in a Lagrangian manner. Using a discrete Lagrangian flow of an axisymmetric vortex-stretching field, the score function is learned with a neural network and employed to construct backward-time particle trajectories. Numerical results demonstrate that information about initial positions is rapidly lost in the compressive direction, whereas it is relatively well preserved in the stretching direction."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00057v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00057v1", "physics": true, "shape": "dot", "size": 6, "title": "Explore Brain-Inspired Machine Intelligence for Connecting Dots on Graphs Through Holographic Blueprint of Oscillatory Synchronization. arXiv:2602.00057v1 Announce Type: cross \nAbstract: Neural coupling in both neuroscience and artificial intelligence emerges as dynamic oscillatory patterns that encode abstract concepts. To this end, we hypothesize that a deeper understanding of the neural mechanisms governing brain rhythms can inspire next-generation design principles for machine learning algorithms, leading to improved efficiency and robustness. Building on this idea, we first model evolving brain rhythms through the interference of spontaneously synchronized neural oscillations, termed HoloBrain. The success of modeling brain rhythms using an artificial dynamical system of coupled oscillations motivates a \"first principle\" for brain-inspired machine intelligence based on a shared synchronization mechanism, termed HoloGraph. This principle enables graph neural networks to move beyond conventional heat diffusion paradigms toward modeling oscillatory synchronization. Our HoloGraph framework not only effectively mitigates the over-smoothing problem in graph neural networks but also demonstrates strong potential for reasoning and solving challenging problems on graphs."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01131v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01131v1", "physics": true, "shape": "dot", "size": 6, "title": "Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach. arXiv:2602.01131v1 Announce Type: new \nAbstract: With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous networks is often compromised by the conflict between limited onboard resources and stringent stability requirements. Moving beyond traditional throughput-centric designs, we propose a Sensing-Communication-Computing-Control closed-loop framework that explicitly models the impact of communication latency on physical control stability. To guarantee mission reliability, we leverage the Lyapunov stability theory to derive an intrinsic mapping between the state evolution of the control system and communication constraints, transforming abstract stability requirements into quantifiable resource boundaries. Then, we formulate the resource allocation problem as a Stackelberg game, where UAVs (as leaders) dynamically price resources to balance load and ensure stability, while users (as followers) optimize requests based on service urgency. Furthermore, addressing the prohibitive computational overhead of standard Deep Reinforcement Learning (DRL) on energy-constrained edge platforms, we propose a novel and lightweight pruning-based Proximal Policy Optimization (PPO) algorithm. By integrating a dynamic structured pruning mechanism, the proposed algorithm significantly compresses the neural network scale during training, enabling the UAV to rapidly approximate the game equilibrium with minimal inference latency. Simulation results demonstrate that the proposed scheme effectively secures control loop stability while maximizing system utility in dynamic low-altitude environments."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22970v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22970v1", "physics": true, "shape": "dot", "size": 6, "title": "Stabilizing the Q-Gradient Field for Policy Smoothness in Actor-Critic. arXiv:2601.22970v1 Announce Type: cross \nAbstract: Policies learned via continuous actor-critic methods often exhibit erratic, high-frequency oscillations, making them unsuitable for physical deployment. Current approaches attempt to enforce smoothness by directly regularizing the policy\u0027s output. We argue that this approach treats the symptom rather than the cause. In this work, we theoretically establish that policy non-smoothness is fundamentally governed by the differential geometry of the critic. By applying implicit differentiation to the actor-critic objective, we prove that the sensitivity of the optimal policy is bounded by the ratio of the Q-function\u0027s mixed-partial derivative (noise sensitivity) to its action-space curvature (signal distinctness). To empirically validate this theoretical insight, we introduce PAVE (Policy-Aware Value-field Equalization), a critic-centric regularization framework that treats the critic as a scalar field and stabilizes its induced action-gradient field. PAVE rectifies the learning signal by minimizing the Q-gradient volatility while preserving local curvature. Experimental results demonstrate that PAVE achieves smoothness and robustness comparable to policy-side smoothness regularization methods, while maintaining competitive task performance, without modifying the actor."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22880v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22880v1", "physics": true, "shape": "dot", "size": 6, "title": "Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems. arXiv:2601.22880v1 Announce Type: cross \nAbstract: We study the joint operation and sizing of cooling infrastructure for commercial HVAC systems using reinforcement learning, with the objective of minimizing life-cycle cost over a 30-year horizon. The cooling system consists of a fixed-capacity electric chiller and a thermal energy storage (TES) unit, jointly operated to meet stochastic hourly cooling demands under time-varying electricity prices. The life-cycle cost accounts for both capital expenditure and discounted operating cost, including electricity consumption and maintenance. A key challenge arises from the strong asymmetry in capital costs: increasing chiller capacity by one unit is far more expensive than an equivalent increase in TES capacity. As a result, identifying the right combination of chiller and TES sizes, while ensuring zero loss-of-cooling-load under optimal operation, is a non-trivial co-design problem. To address this, we formulate the chiller operation problem for a fixed infrastructure configuration as a finite-horizon Markov Decision Process (MDP), in which the control action is the chiller part-load ratio (PLR). The MDP is solved using a Deep Q Network (DQN) with a constrained action space. The learned DQN RL policy minimizes electricity cost over historical traces of cooling demand and electricity prices. For each candidate chiller-TES sizing configuration, the trained policy is evaluated. We then restrict attention to configurations that fully satisfy the cooling demand and perform a life-cycle cost minimization over this feasible set to identify the cost-optimal infrastructure design. Using this approach, we determine the optimal chiller and thermal energy storage capacities to be 700 and 1500, respectively."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22865v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22865v1", "physics": true, "shape": "dot", "size": 6, "title": "Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning. arXiv:2601.22865v1 Announce Type: cross \nAbstract: Battery energy storage systems are increasingly deployed as fast-responding resources for grid balancing services such as frequency regulation and for mitigating renewable generation uncertainty. However, repeated charging and discharging induces cycling degradation and reduces battery lifetime. This paper studies the real-time scheduling of a heterogeneous battery fleet that collectively tracks a stochastic balancing signal subject to per-battery ramp-rate and capacity constraints, while minimizing long-term cycling degradation.\n  Cycling degradation is fundamentally path-dependent: it is determined by charge-discharge cycles formed by the state-of-charge (SoC) trajectory and is commonly quantified via rainflow cycle counting. This non-Markovian structure makes it difficult to express degradation as an additive per-time-step cost, complicating classical dynamic programming approaches. We address this challenge by formulating the fleet scheduling problem as a Markov decision process (MDP) with constrained action space and designing a dense proxy reward that provides informative feedback at each time step while remaining aligned with long-term cycle-depth reduction.\n  To scale learning to large state-action spaces induced by fine-grained SoC discretization and asymmetric per-battery constraints, we develop a function-approximation reinforcement learning method using an Extreme Learning Machine (ELM) as a random nonlinear feature map combined with linear temporal-difference learning. We evaluate the proposed approach on a toy Markovian signal model and on a Markovian model trained from real-world regulation signal traces obtained from the University of Delaware, and demonstrate consistent reductions in cycle-depth occurrence and degradation metrics compared to baseline scheduling policies."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22409v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22409v1", "physics": true, "shape": "dot", "size": 6, "title": "Optimization, Generalization and Differential Privacy Bounds for Gradient Descent on Kolmogorov-Arnold Networks. arXiv:2601.22409v1 Announce Type: cross \nAbstract: Kolmogorov--Arnold Networks (KANs) have recently emerged as a structured alternative to standard MLPs, yet a principled theory for their training dynamics, generalization, and privacy properties remains limited. In this paper, we analyze gradient descent (GD) for training two-layer KANs and derive general bounds that characterize their training dynamics, generalization, and utility under differential privacy (DP). As a concrete instantiation, we specialize our analysis to logistic loss under an NTK-separable assumption, where we show that polylogarithmic network width suffices for GD to achieve an optimization rate of order $1/T$ and a generalization rate of order $1/n$, with $T$ denoting the number of GD iterations and $n$ the sample size. In the private setting, we characterize the noise required for $(\\epsilon,\\delta)$-DP and obtain a utility bound of order $\\sqrt{d}/(n\\epsilon)$ (with $d$ the input dimension), matching the classical lower bound for general convex Lipschitz problems. Our results imply that polylogarithmic width is not only sufficient but also necessary under differential privacy, revealing a qualitative gap between non-private (sufficiency only) and private (necessity also emerges) training regimes. Experiments further illustrate how these theoretical insights can guide practical choices, including network width selection and early stopping."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22400v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22400v1", "physics": true, "shape": "dot", "size": 6, "title": "Spectral Filtering for Learning Quantum Dynamics. arXiv:2601.22400v1 Announce Type: cross \nAbstract: Learning high-dimensional quantum systems is a fundamental challenge that notoriously suffers from the curse of dimensionality. We formulate the task of predicting quantum evolution in the linear response regime as a specific instance of learning a Complex-Valued Linear Dynamical System (CLDS) with sector-bounded eigenvalues -- a setting that also encompasses modern Structured State Space Models (SSMs). While traditional system identification attempts to reconstruct full system matrices (incurring exponential cost in the Hilbert dimension), we propose Quantum Spectral Filtering, a method that shifts the goal to improper dynamic learning. Leveraging the optimal concentration properties of the Slepian basis, we prove that the learnability of such systems is governed strictly by an effective quantum dimension $k^*$, determined by the spectral bandwidth and memory horizon. This result establishes that complex-valued LDSs can be learned with sample and computational complexity independent of the ambient state dimension, provided their spectrum is bounded."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20174v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20174v1", "physics": true, "shape": "dot", "size": 6, "title": "NeuraLSP: An Efficient and Rigorous Neural Left Singular Subspace Preconditioner for Conjugate Gradient Methods. arXiv:2601.20174v1 Announce Type: cross \nAbstract: Numerical techniques for solving partial differential equations (PDEs) are integral for many fields across science and engineering. Such techniques usually involve solving large, sparse linear systems, where preconditioning methods are critical. In recent years, neural methods, particularly graph neural networks (GNNs), have demonstrated their potential through accelerated convergence. Nonetheless, to extract connective structures, existing techniques aggregate discretized system matrices into graphs, and suffer from rank inflation and a suboptimal convergence rate. In this paper, we articulate NeuraLSP, a novel neural preconditioner combined with a novel loss metric that leverages the left singular subspace of the system matrix\u0027s near-nullspace vectors. By compressing spectral information into a fixed low-rank operator, our method exhibits both theoretical guarantees and empirical robustness to rank inflation, affording up to a 53% speedup. Besides the theoretical guarantees for our newly-formulated loss function, our comprehensive experimental results across diverse families of PDEs also substantiate the aforementioned theoretical advances."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.21288v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.21288v3", "physics": true, "shape": "dot", "size": 6, "title": "SpringTime: Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties. arXiv:2507.21288v3 Announce Type: replace-cross \nAbstract: Materials used in real clothing exhibit remarkable complexity and spatial variation due to common processes such as stitching, hemming, dyeing, printing, padding, and bonding. Simulating these materials, for instance using finite element methods, is often computationally demanding and slow. Worse, such methods can suffer from numerical artifacts called ``membrane locking\u0027\u0027 that makes cloth appear artificially stiff. Here we propose a general framework, called SpringTime, for learning a simple yet efficient surrogate model that captures the effects of these complex materials using only motion observations. The cloth is discretized into a mass-spring network with unknown material parameters that are learned directly from the motion data, using a novel force-and-impulse loss function. Our approach demonstrates the ability to accurately model spatially varying material properties from a variety of data sources, and immunity to membrane locking which plagues FEM-based simulations. Compared to graph-based networks and neural ODE-based architectures, our method achieves significantly faster training times, higher reconstruction accuracy, and improved generalization to novel dynamic scenarios. Codebase for the paper can be found at https://github.com/ericchen321/springtime."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18264v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18264v1", "physics": true, "shape": "dot", "size": 6, "title": "Neural Network Approximation: A View from Polytope Decomposition. arXiv:2601.18264v1 Announce Type: cross \nAbstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17090v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17090v1", "physics": true, "shape": "dot", "size": 6, "title": "SFO: Learning PDE Operators via Spectral Filtering. arXiv:2601.17090v1 Announce Type: cross \nAbstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green\u0027s functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.13732v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.13732v2", "physics": true, "shape": "dot", "size": 6, "title": "PIS: A Generalized Physical Inversion Solver for Arbitrary Sparse Observations via Set Conditioned Flow Matching. arXiv:2512.13732v2 Announce Type: replace-cross \nAbstract: The estimation of high-dimensional physical parameters constrained by partial differential equations (PDEs) from limited and indirect measurements is a highly ill-posed problem. Traditional methods face significant accuracy and efficiency bottlenecks, particularly when observations are sparse, irregularly sampled, and constrained by real-world sensor placement. We propose the Physical Inversion Solver (PIS), a unified framework that couples Set-Conditioned Flow Matching with a Cosine-Annealed Sparsity Curriculum (CASC) to enable stable inversion from arbitrary, off-grid sensors even under minimal guidance. By leveraging straight-path transport, PIS achieves instantaneous inference (50 NFEs), offering orders-of-magnitude speedup over iterative baselines. Extensive experiments demonstrate that PIS reduces error by up to 88.7% under extreme sparsity (\u003c1%) across subsurface characterization, wave-based characterization, and structural health monitoring, while providing robust uncertainty quantification for optimal sensor placement."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "label": "Interpretability Science: Tracking Token-Level Logic in Large Models", "physics": true, "shape": "dot", "size": 61, "title": "Interpretability Science: Tracking Token-Level Logic in Large Models (5 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2406.09260v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2406.09260v3", "physics": true, "shape": "dot", "size": 6, "title": "Deep Transformer Network for Monocular Pose Estimation of Shipborne Unmanned Aerial Vehicle. arXiv:2406.09260v3 Announce Type: replace-cross \nAbstract: This paper introduces a deep transformer network for estimating the relative 6D pose of a Unmanned Aerial Vehicle (UAV) with respect to a ship using monocular images. A synthetic dataset of ship images is created and annotated with 2D keypoints of multiple ship parts. A Transformer Neural Network model is trained to detect these keypoints and estimate the 6D pose of each part. The estimates are integrated using Bayesian fusion. The model is tested on synthetic data and in-situ flight experiments, demonstrating robustness and accuracy in various lighting conditions. The position estimation error is approximately 0.8\\% and 1.0\\% of the distance to the ship for the synthetic data and the flight experiments, respectively. The method has potential applications for ship-based autonomous UAV landing and navigation."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00184v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00184v1", "physics": true, "shape": "dot", "size": 6, "title": "Visible Singularities Guided Correlation Network for Limited-Angle CT Reconstruction. arXiv:2602.00184v1 Announce Type: cross \nAbstract: Limited-angle computed tomography (LACT) offers the advantages of reduced radiation dose and shortened scanning time. Traditional reconstruction algorithms exhibit various inherent limitations in LACT. Currently, most deep learning-based LACT reconstruction methods focus on multi-domain fusion or the introduction of generic priors, failing to fully align with the core imaging characteristics of LACT-such as the directionality of artifacts and directional loss of structural information, which are caused by the absence of projection angles in certain directions. Inspired by the theory of visible and invisible singularities, taking into account the aforementioned core imaging characteristics of LACT, we propose a Visible Singularities Guided Correlation network for LACT reconstruction (VSGC). The design philosophy of VSGC consists of two core steps: First, extract VS edge features from LACT images and focus the model\u0027s attention on these VS. Second, establish correlations between the VS edge features and other regions of the image. Additionally, a multi-scale loss function with anisotropic constraint is employed to constrain the model to converge in multiple aspects. Finally, qualitative and quantitative validations are conducted on both simulated and real datasets to verify the effectiveness and feasibility of the proposed design. Particularly, in comparison with alternative methods, VSGC delivers more prominent performance in small angular ranges, with the PSNR improvement of 2.45 dB and the SSIM enhancement of 1.5\\%. The code is publicly available at https://github.com/yqx7150/VSGC."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00153v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00153v1", "physics": true, "shape": "dot", "size": 6, "title": "See Without Decoding: Motion-Vector-Based Tracking in Compressed Video. arXiv:2602.00153v1 Announce Type: cross \nAbstract: We propose a lightweight compressed-domain tracking model that operates directly on video streams, without requiring full RGB video decoding. Using motion vectors and transform coefficients from compressed data, our deep model propagates object bounding boxes across frames, achieving a computational speed-up of order up to 3.7 with only a slight 4% mAP@0.5 drop vs RGB baseline on MOTS15/17/20 datasets. These results highlight codec-domain motion modeling efficiency for real-time analytics in large monitoring systems."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12257v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12257v1", "physics": true, "shape": "dot", "size": 6, "title": "Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy. arXiv:2601.12257v1 Announce Type: cross \nAbstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \\textit{light-occluding} and \\textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16336v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16336v2", "physics": true, "shape": "dot", "size": 6, "title": "DMAVA: Distributed Multi-Autonomous Vehicle Architecture Using Autoware. arXiv:2601.16336v2 Announce Type: replace-cross \nAbstract: Simulating and validating coordination among multiple autonomous vehicles remains challenging, as many existing simulation architectures are limited to single-vehicle operation or rely on centralized control. This paper presents the Distributed Multi-Autonomous Vehicle Architecture (DMAVA), a simulation architecture that enables concurrent execution of multiple independent vehicle autonomy stacks distributed across multiple physical hosts within a shared simulation environment. Each vehicle operates its own complete autonomous driving stack while maintaining coordinated behavior through a data-centric communication layer. The proposed system integrates ROS 2 Humble, Autoware Universe, AWSIM Labs, and Zenoh to support high data accuracy and controllability during multi-vehicle simulation, enabling consistent perception, planning, and control behavior under distributed execution. Experiments conducted on multiple-host configurations demonstrate stable localization, reliable inter-host communication, and consistent closed-loop control under distributed execution. DMAVA also serves as a foundation for Multi-Vehicle Autonomous Valet Parking, demonstrating its extensibility toward higher-level cooperative autonomy. Demo videos and source code are available at: https://github.com/zubxxr/distributed-multi-autonomous-vehicle-architecture."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16327v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16327v2", "physics": true, "shape": "dot", "size": 6, "title": "DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking Using Autoware. arXiv:2601.16327v2 Announce Type: replace-cross \nAbstract: This paper presents DMV-AVP, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Autonomous Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of DMAVA: 1) the Multi-Vehicle AVP Coordination Framework, composed of AVP Managers and a per-vehicle AVP Node, is responsible for global parking state tracking, vehicle queuing, parking spot reservation, lifecycle coordination, and conflict resolution across multiple vehicles, and 2) the Unity-Integrated YOLOv5 Parking Spot Detection Module, that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh communication layer that ensures high data accuracy and controllability across hosts. Experiments conducted on two- and three-host configurations demonstrate consistent coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed DMV-AVP supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at: https://github.com/zubxxr/multi-vehicle-avp"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "label": "Advanced Computing Solves Toughest Optimization and Resource Problems.", "physics": true, "shape": "dot", "size": 80, "title": "Advanced Computing Solves Toughest Optimization and Resource Problems. (20 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.00521v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.00521v2", "physics": true, "shape": "dot", "size": 6, "title": "Probability-Aware Parking Selection. arXiv:2601.00521v2 Announce Type: replace-cross \nAbstract: Current navigation systems conflate time-to-drive with the true time-to-arrive by ignoring parking search duration and the final walking leg. Such underestimation can significantly affect user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed that leverages probabilistic, lot-level availability to minimize the expected time-to-arrive. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model\u0027s ability to account for the dynamic nature of parking availability. Given the high cost of permanent sensing infrastructure, we assess the error rates of using stochastic observations to estimate availability. Experiments with real-world data from the US city of Seattle indicate this approach\u0027s viability, with mean absolute error decreasing from 7% to below 2% as observation frequency increases. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than time-to-drive estimates."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.08659v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.08659v2", "physics": true, "shape": "dot", "size": 6, "title": "Introduction to Automated Negotiation. arXiv:2511.08659v2 Announce Type: replace-cross \nAbstract: This book is an introductory textbook targeted towards computer science students who are completely new to the topic of automated negotiation. It does not require any prerequisite knowledge, except for elementary mathematics and basic programming skills.\n  This book comes with an simple toy-world negotiation framework implemented in Python that can be used by the readers to implement their own negotiation algorithms and perform experiments with them. This framework is small and simple enough that any reader who does not like to work in Python should be able to re-implement it very quickly in any other programming language of their choice."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.02158v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.02158v1", "physics": true, "shape": "dot", "size": 6, "title": "Traffic-Aware Navigation in Road Networks. arXiv:2602.02158v1 Announce Type: new \nAbstract: This project compares three graph search approaches for the task of traffic-aware navigation in Kingston\u0027s road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra\u0027s and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen\u0027s). Dijkstra\u0027s and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen\u0027s algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22419v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22419v1", "physics": true, "shape": "dot", "size": 6, "title": "Dynamic Welfare-Maximizing Pooled Testing. arXiv:2601.22419v1 Announce Type: cross \nAbstract: Pooled testing is a common strategy for public health disease screening under limited testing resources, allowing multiple biological samples to be tested together with the resources of a single test, at the cost of reduced individual resolution. While dynamic and adaptive strategies have been extensively studied in the classical pooled testing literature, where the goal is to minimize the number of tests required for full diagnosis of a given population, much of the existing work on welfare-maximizing pooled testing adopts static formulations in which all tests are assigned in advance. In this paper, we study dynamic welfare-maximizing pooled testing strategies in which a limited number of tests are performed sequentially to maximize social welfare, defined as the aggregate utility of individuals who are confirmed to be healthy. We formally define the dynamic problem and study algorithmic approaches for sequential test assignment. Because exact dynamic optimization is computationally infeasible beyond small instances, we evaluate a range of strategies (including exact optimization baselines, greedy heuristics, mixed-integer programming relaxations, and learning-based policies) and empirically characterize their performance and tradeoffs using synthetic experiments. Our results show that dynamic testing can yield substantial welfare improvements over static baselines in low-budget regimes. We find that much of the benefit of dynamic testing is captured by simple greedy policies, which substantially outperform static approaches while remaining computationally efficient. Learning-based methods are included as flexible baselines, but in our experiments they do not reliably improve upon these heuristics. Overall, this work provides a principled computational perspective on dynamic pooled testing and clarifies when dynamic assignment meaningfully improves welfare in public health screening."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22183v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22183v1", "physics": true, "shape": "dot", "size": 6, "title": "COL-Trees: Efficient Hierarchical Object Search in Road Networks. arXiv:2601.22183v1 Announce Type: cross \nAbstract: Location-based services rely heavily on efficient methods that search for relevant points-of-interest (POIs) near a given location. A k Nearest Neighbor (kNN) query is one such example that finds the k closest POIs from an agent\u0027s location. While most existing techniques focus on retrieving nearby POIs for a single agent, these search heuristics do not translate to many other applications. For example, Aggregate k Nearest Neighbor (AkNN) queries require POIs that are close to multiple agents. k Farthest Neighbor (kFN) queries require POIs that are the antithesis of nearest. Such problems naturally benefit from a hierarchical approach, but existing methods rely on Euclidean-based heuristics, which have diminished effectiveness in graphs such as road networks. We propose a novel data structure, COL-Tree (Compacted Object-Landmark Tree), to address this gap by enabling efficient hierarchical graph traversal using a more accurate landmark-based heuristic. We then present query algorithms that utilize COL-Trees to efficiently answer AkNN, kFN, and other queries. In our experiments on real-world and synthetic datasets, we demonstrate that our techniques significantly outperform existing approaches, achieving up to 4 orders of magnitude improvement. Moreover, this comes at a small pre-processing overhead in both theory and practice."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2405.10377v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2405.10377v1", "physics": true, "shape": "dot", "size": 6, "title": "Smart Routing with Precise Link Estimation: DSEE-Based Anypath Routing for Reliable Wireless Networking. arXiv:2405.10377v1 Announce Type: cross \nAbstract: In dynamic and resource-constrained environments, such as multi-hop wireless mesh networks, traditional routing protocols often falter by relying on predetermined paths that prove ineffective in unpredictable link conditions. Shortest Anypath routing offers a solution by adapting routing decisions based on real-time link conditions. However, the effectiveness of such routing is fundamentally dependent on the quality and reliability of the available links, and predicting these variables with certainty is challenging. This paper introduces a novel approach that leverages the Deterministic Sequencing of Exploration and Exploitation (DSEE), a multi-armed bandit algorithm, to address the need for accurate and real-time estimation of link delivery probabilities. This approach augments the reliability and resilience of the Shortest Anypath routing in the face of fluctuating link conditions. By coupling DSEE with Anypath routing, this algorithm continuously learns and ensures accurate delivery probability estimation and selects the most suitable way to efficiently route packets while maintaining a provable near-logarithmic regret bound. We also theoretically prove that our proposed scheme offers better regret scaling with respect to the network size than the previously proposed Thompson Sampling-based Opportunistic Routing (TSOR)."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.23229v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.23229v1", "physics": true, "shape": "dot", "size": 6, "title": "Strongly Polynomial Time Complexity of Policy Iteration for $L_\\infty$ Robust MDPs. arXiv:2601.23229v1 Announce Type: new \nAbstract: Markov decision processes (MDPs) are a fundamental model in sequential decision making. Robust MDPs (RMDPs) extend this framework by allowing uncertainty in transition probabilities and optimizing against the worst-case realization of that uncertainty. In particular, $(s, a)$-rectangular RMDPs with $L_\\infty$ uncertainty sets form a fundamental and expressive model: they subsume classical MDPs and turn-based stochastic games. We consider this model with discounted payoffs. The existence of polynomial and strongly-polynomial time algorithms is a fundamental problem for these optimization models. For MDPs, linear programming yields polynomial-time algorithms for any arbitrary discount factor, and the seminal work of Ye established strongly--polynomial time for a fixed discount factor. The generalization of such results to RMDPs has remained an important open problem. In this work, we show that a robust policy iteration algorithm runs in strongly-polynomial time for $(s, a)$-rectangular $L_\\infty$ RMDPs with a constant (fixed) discount factor, resolving an important algorithmic question."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.15824v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.15824v2", "physics": true, "shape": "dot", "size": 6, "title": "State-Augmented Graphs for Circular Economy Triage. arXiv:2512.15824v2 Announce Type: replace \nAbstract: Circular economy (CE) triage is the assessment of products to determine which sustainable pathway they can follow once they reach the end of their usefulness as they are currently being used. Effective CE triage requires adaptive decisions that balance retained value against the costs and constraints of processing and labour. This paper presents a novel decision-making framework as a simple deterministic solver over a state-augmented Disassembly Sequencing Planning (DSP) graph. By encoding the disassembly history into the state, our framework enforces the Markov property, enabling optimal, recursive evaluation by ensuring each decision only depends on the previous state. The triage decision involves choices between continuing disassembly or committing to a CE option. The model integrates condition-aware utility based on diagnostic health scores and complex operational constraints. We demonstrate the framework\u0027s flexibility with a worked example: the hierarchical triage of electric vehicle (EV) batteries, where decisions are driven by the recursive valuation of components. The example illustrates how a unified formalism enables the accommodation of varying mechanical complexity, safety requirements, and economic drivers. This unified formalism therefore provides a tractable and generalisable foundation for optimising CE triage decisions across diverse products and operational contexts."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20735v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20735v1", "physics": true, "shape": "dot", "size": 6, "title": "Implementing Metric Temporal Answer Set Programming. arXiv:2601.20735v1 Announce Type: new \nAbstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP\u0027s grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06188v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06188v2", "physics": true, "shape": "dot", "size": 6, "title": "Large-Scale Continual Scheduling and Execution for Dynamic Distributed Satellite Constellation Observation Allocation. arXiv:2601.06188v2 Announce Type: replace \nAbstract: The size and capabilities of Earth-observing satellite constellations are rapidly increasing. Leveraging distributed onboard control, we can enable novel time-sensitive measurements and responses. However, deploying autonomy to large multiagent satellite systems necessitates algorithms with efficient computation and communication. We tackle this challenge and propose new, online algorithms for large-scale dynamic distributed constraint optimization problems (DDCOP). We present the Dynamic Multi-Satellite Constellation Observation Scheduling Problem (DCOSP), a new formulation of DDCOPs that models integrated scheduling and execution. We construct an omniscient offline algorithm to compute the novel optimality condition of DCOSP and present the Dynamic Incremental Neighborhood Stochastic Search (D-NSS) algorithm, an incomplete online decomposition-based DDCOP approach. We show through simulation that D-NSS converges to near-optimal solutions and outperforms DDCOP baselines in terms of solution quality, computation time, and message volume. Our work forms the foundation of the largest in-space demonstration of distributed multiagent AI to date: the NASA FAME mission."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01832v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01832v2", "physics": true, "shape": "dot", "size": 6, "title": "Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization. arXiv:2601.01832v2 Announce Type: replace-cross \nAbstract: We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization.\n  We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2506.06216v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2506.06216v3", "physics": true, "shape": "dot", "size": 6, "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability. arXiv:2506.06216v3 Announce Type: replace \nAbstract: The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge with numerous practical applications. In recent MaxSAT evaluations, most MaxSAT solvers have incorporated an Integer Linear Programming (ILP) solver into their portfolios. However, a good portfolio strategy requires a lot of tuning work and is limited to the profiling benchmark. This paper proposes a methodology to fully integrate ILP preprocessing techniques into the MaxSAT solving pipeline and investigates the impact on the top-performing MaxSAT solvers. Experimental results show that our approach helps to improve 5 out of 6 state-of-the-art MaxSAT solvers, especially for WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024 on the unweighted track, which is able to solve 15 additional instances using our methodology."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17028v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17028v1", "physics": true, "shape": "dot", "size": 6, "title": "PALMA: A Lightweight Tropical Algebra Library for ARM-Based Embedded Systems. arXiv:2601.17028v1 Announce Type: cross \nAbstract: Tropical algebra, including max-plus, min-plus, and related idempotent semirings, provides a unifying framework in which many optimization problems that are nonlinear in classical algebra become linear. This property makes tropical methods particularly well suited for shortest paths, scheduling, throughput analysis, and discrete event systems. Despite their theoretical maturity and practical relevance, existing tropical algebra implementations primarily target desktop or server environments and remain largely inaccessible on resource-constrained embedded platforms, where such optimization problems are most acute. We present PALMA (Parallel Algebra Library for Max-plus Applications), a lightweight, dependency-free C library that brings tropical linear algebra to ARM-based embedded systems. PALMA implements a generic semiring abstraction with SIMD-accelerated kernels, enabling a single computational framework to support shortest paths, bottleneck paths, reachability, scheduling, and throughput analysis. The library supports five tropical semirings, dense and sparse (CSR) representations, tropical closure, and spectral analysis via maximum cycle mean computation. We evaluate PALMA on a Raspberry Pi 4 and demonstrate peak performance of 2,274 MOPS, speedups of up to 11.9 times over classical Bellman-Ford for single-source shortest paths, and sub-10 microsecond scheduling solves for real-time control workloads. Case studies in UAV control, IoT routing, and manufacturing systems show that tropical algebra enables efficient, predictable, and unified optimization directly on embedded hardware. PALMA is released as open-source software under the MIT license."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.09808v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.09808v2", "physics": true, "shape": "dot", "size": 6, "title": "Constrained Best Arm Identification with Tests for Feasibility. arXiv:2511.09808v2 Announce Type: replace-cross \nAbstract: Best arm identification (BAI) aims to identify the highest-performance arm among a set of $K$ arms by collecting stochastic samples from each arm. In real-world problems, the best arm needs to satisfy additional feasibility constraints. While there is limited prior work on BAI with feasibility constraints, they typically assume the performance and constraints are observed simultaneously on each pull of an arm. However, this assumption does not reflect most practical use cases, e.g., in drug discovery, we wish to find the most potent drug whose toxicity and solubility are below certain safety thresholds. These safety experiments can be conducted separately from the potency measurement. Thus, this requires designing BAI algorithms that not only decide which arm to pull but also decide whether to test for the arm\u0027s performance or feasibility. In this work, we study feasible BAI which allows a decision-maker to choose a tuple $(i,\\ell)$, where $i\\in [K]$ denotes an arm and $\\ell$ denotes whether she wishes to test for its performance ($\\ell=0$) or any of its $N$ feasibility constraints ($\\ell\\in[N]$). We focus on the fixed confidence setting, which is to identify the feasible arm with the highest performance, with a probability of at least $1-\\delta$. We propose an efficient algorithm and upper-bound its sample complexity, showing our algorithm can naturally adapt to the problem\u0027s difficulty and eliminate arms by worse performance or infeasibility, whichever is easier. We complement this upper bound with a lower bound showing that our algorithm is \\textit{asymptotically ($\\delta\\rightarrow 0$) optimal}. Finally, we empirically show that our algorithm outperforms other state-of-the-art BAI algorithms in both synthetic and real-world datasets."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16855v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16855v1", "physics": true, "shape": "dot", "size": 6, "title": "Orbitopal Fixing in SAT. arXiv:2601.16855v1 Announce Type: cross \nAbstract: Despite their sophisticated heuristics, boolean satisfiability (SAT) solvers are still vulnerable to symmetry, causing them to visit search regions that are symmetric to ones already explored. While symmetry handling is routine in other solving paradigms, integrating it into state-of-the-art proof-producing SAT solvers is difficult: added reasoning must be fast, non-interfering with solver heuristics, and compatible with formal proof logging. To address these issues, we present a practical static symmetry breaking approach based on orbitopal fixing, a technique adapted from mixed-integer programming. Our approach adds only unit clauses, which minimizes downstream slowdowns, and it emits succinct proof certificates in the substitution redundancy proof system. Implemented in the satsuma tool, our methods deliver consistent speedups on symmetry-rich benchmarks with negligible regressions elsewhere."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14476v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14476v1", "physics": true, "shape": "dot", "size": 6, "title": "GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling. arXiv:2601.14476v1 Announce Type: cross \nAbstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -- timing, intensity, and offset -- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14784v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14784v1", "physics": true, "shape": "dot", "size": 6, "title": "Towards Bound Consistency for the No-Overlap Constraint Using MDDs. arXiv:2601.14784v1 Announce Type: new \nAbstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Cir\\\u0027e and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \\mid r_j, d_j, \\bar{d}_j \\mid \\sum E_j + \\sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Cir\\\u0027e and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14485v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14485v1", "physics": true, "shape": "dot", "size": 6, "title": "Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling. arXiv:2601.14485v1 Announce Type: new \nAbstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11883v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11883v2", "physics": true, "shape": "dot", "size": 6, "title": "Position: Universal Aesthetic Alignment Narrows Artistic Expression. arXiv:2512.11883v2 Announce Type: replace-cross \nAbstract: Over-aligning image generation models to a generalized aesthetic preference conflicts with user intent, particularly when \"anti-aesthetic\" outputs are requested for artistic or critical purposes. This adherence prioritizes developer-centered values, compromising user autonomy and aesthetic pluralism. We test this bias by constructing a wide-spectrum aesthetics dataset and evaluating state-of-the-art generation and reward models. This position paper finds that aesthetic-aligned generation models frequently default to conventionally beautiful outputs, failing to respect instructions for low-quality or negative imagery. Crucially, reward models penalize anti-aesthetic images even when they perfectly match the explicit user prompt. We confirm this systemic bias through image-to-image editing and evaluation against real abstract artworks."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "label": "AI: Crafting Interactive Stories and Personalized Creative Expression.", "physics": true, "shape": "dot", "size": 70, "title": "AI: Crafting Interactive Stories and Personalized Creative Expression. (10 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v2", "physics": true, "shape": "dot", "size": 6, "title": "Student Perceptions of Large Language Models Use in Self-Reflection and Design Critique in Architecture Studio. arXiv:2602.00041v2 Announce Type: cross \nAbstract: This study investigates the integration of Large Language Models (LLMs) into the feedback mechanisms of the architectural design studio, shifting the focus from generative production to reflective pedagogy. Employing a mixed-methods approach with surveys and semi structured interviews with 22 architecture students at the Singapore University of Technology and De-sign, the research analyzes student perceptions across three distinct feed-back domains: self-reflection, peer critique, and professor-led reviews. The findings reveal that students engage with LLMs not as authoritative in-structors, but as collaborative \"cognitive mirrors\" that scaffold critical thinking. In self-directed learning, LLMs help structure thoughts and over-come the \"blank page\" problem, though they are limited by a lack of contex-tual nuance. In peer critiques, the technology serves as a neutral mediator, mitigating social anxiety and the \"fear of offending\". Furthermore, in high-stakes professor-led juries, students utilize LLMs primarily as post-critique synthesis engines to manage cognitive overload and translate ab-stract academic discourse into actionable design iterations."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v1", "physics": true, "shape": "dot", "size": 6, "title": "Student Perceptions of Large Language Models Use in Self-Reflection and Design Critique in Architecture Studio. arXiv:2602.00041v1 Announce Type: cross \nAbstract: This study investigates the integration of Large Language Models (LLMs) into the feedback mechanisms of the architectural design studio, shifting the focus from generative production to reflective pedagogy. Employing a mixed-methods approach with architecture students at the Singapore Uni-versity of Technology and Design, the research analyzes student percep-tions across three distinct feedback domains: self-reflection, peer critique, and professor-led reviews. The findings reveal that students engage with LLMs not as authoritative instructors, but as collaborative \"cognitive mir-rors\" that scaffold critical thinking. In self-directed learning, LLMs help structure thoughts and overcome the \"blank page\" problem, though they are limited by a lack of contextual nuance. In peer critiques, the technology serves as a neutral mediator, mitigating social anxiety and the \"fear of of-fending\". Furthermore, in high-stakes professor-led juries, students utilize LLMs primarily as post-critique synthesis engines to manage cognitive overload and translate abstract academic discourse into actionable design iterations."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v3", "physics": true, "shape": "dot", "size": 6, "title": "Autiverse: Eliciting Autistic Adolescents\u0027 Daily Narratives through AI-guided Multimodal Journaling. arXiv:2509.17466v3 Announce Type: replace-cross \nAbstract: Journaling can potentially serve as an effective method for autistic adolescents to improve narrative skills. However, its text-centric nature and high executive functioning demands present barriers to practice. We present Autiverse, an AI-guided multimodal journaling app for tablets that scaffolds daily narratives through conversational prompts and visual supports. Autiverse elicits key details of an adolescent-selected event through a stepwise dialogue with peer-like, customizable AI and composes them into an editable four-panel comic strip. Through a two-week deployment study with 10 autistic adolescent-parent dyads, we examine how Autiverse supports autistic adolescents to organize their daily experience and emotion. Our findings show Autiverse scaffolded adolescents\u0027 coherent narratives, while enabling parents to learn additional details of their child\u0027s events and emotions. Moreover, the customized AI peer created a comfortable space for sharing, fostering enjoyment and a strong sense of agency. Drawing on these results, we discuss implications for adaptive scaffolding across autism profiles, socio-emotionally appropriate AI peer design, and balancing autonomy with parental involvement."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v2", "physics": true, "shape": "dot", "size": 6, "title": "Autiverse: Eliciting Autistic Adolescents\u0027 Daily Narratives through AI-guided Multimodal Journaling. arXiv:2509.17466v2 Announce Type: replace-cross \nAbstract: Journaling can potentially serve as an effective method for autistic adolescents to improve narrative skills. However, its text-centric nature and high executive functioning demands present barriers to practice. We present Autiverse, an AI-guided multimodal journaling app for tablets that scaffolds storytelling through conversational prompts and visual supports. Autiverse elicits key details through a stepwise dialogue with peer-like, customizable AI and composes them into an editable four-panel comic strip. Through a two-week deployment study with 10 autistic adolescent-parent dyads, we examine how Autiverse supports autistic adolescents to organize their daily experience and emotion. Autiverse scaffolded adolescents\u0027 coherent narratives, while enabling parents to learn additional details of their child\u0027s events and emotions. The customized AI peer created a comfortable space for sharing, fostering enjoyment and a strong sense of agency. We discuss implications for adaptive scaffolding across autism profiles, socio-emotionally appropriate AI peer design, and balancing autonomy with parental involvement."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.15783v4", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.15783v4", "physics": true, "shape": "dot", "size": 6, "title": "Understanding Teen Overreliance on AI Companion Chatbots Through Self-Reported Reddit Narratives. arXiv:2507.15783v4 Announce Type: replace-cross \nAbstract: AI companion chatbots are increasingly popular with teens. While these interactions are entertaining, they also risk overuse that can potentially disrupt offline daily life. We examined how adolescents describe reliance on AI companions, mapping their experiences onto behavioral addiction frameworks and exploring pathways to disengagement, by analyzing 318 Reddit posts made by users who self-disclosed as 13-17 years old on the Character.AI subreddit. We found teens often begin using chatbots for support or creative play, but these activities can deepen into strong attachments marked by conflict, withdrawal, tolerance, relapse, and mood regulation. Reported consequences include sleep loss, academic decline, and strained real-world connections. Disengagement commonly arises when teens recognize harm, re-engage with offline life, or encounter restrictive platform changes. We highlight specific risks of character-based companion chatbots based on teens\u0027 perspectives and introduce a design framework (CARE) for guidance for safer systems and setting directions for future teen-centered research."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18785v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18785v1", "physics": true, "shape": "dot", "size": 6, "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System. arXiv:2601.18785v1 Announce Type: cross \nAbstract: The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14931v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14931v1", "physics": true, "shape": "dot", "size": 6, "title": "Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali. arXiv:2601.14931v1 Announce Type: cross \nAbstract: This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14401v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14401v1", "physics": true, "shape": "dot", "size": 6, "title": "Recursivism: An Artistic Paradigm for Self-Transforming Art in the Age of AI. arXiv:2601.14401v1 Announce Type: cross \nAbstract: This article introduces Recursivism as a conceptual framework for analyzing contemporary artistic practices in the age of artificial intelligence. While recursion is precisely defined in mathematics and computer science, it has not previously been formalized as an aesthetic paradigm. Recursivism designates practices in which not only outputs vary over time, but in which the generative process itself becomes capable of reflexive modification through its own effects.\n  The paper develops a five-level analytical scale distinguishing simple iteration, cumulative iteration, parametric recursion, reflexive recursion, and meta-recursion. This scale clarifies the threshold at which a system shifts from variation within a fixed rule to genuine self-modification of the rule itself. From this perspective, art history is reinterpreted as a recursive dynamic alternating between internal recursion within movements and meta-recursive transformations of their generative principles.\n  Artificial intelligence renders this logic technically explicit through learning loops, parameter updates, and code-level self-modification. To distinguish Recursivism from related notions such as generative art, cybernetics, process art, and evolutionary art, the article proposes three operational criteria: state memory, rule evolvability, and reflexive visibility. These concepts are examined through case studies including Refik Anadol, Sougwen Chung, Karl Sims, and the Darwin-Godel Machine. The article concludes by examining the aesthetic, curatorial, and ethical implications of self-modifying artistic systems."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14265v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14265v1", "physics": true, "shape": "dot", "size": 6, "title": "From Textbook to Talkbot: A Case Study of a Greek-Language RAG-Based Chatbot in Higher Education. arXiv:2601.14265v1 Announce Type: cross \nAbstract: The integration of AI chatbots into educational settings has opened new pathways for transforming teaching and learning, offering enhanced support to both educators and learners. This study investigates the design and application of an AI chatbot as an educational tool in higher education. Designed to operate in the Greek language, the chatbot addresses linguistic challenges unique to Greek while delivering accurate, context grounded support aligned with the curriculum. The AI chatbot is built on the Retrieval Augmented Generation (RAG) framework by grounding its responses in specific course content. RAG architecture significantly enhances the chatbots reliability by providing accurate, context-aware responses while mitigating common challenges associated with large language models (LLMs), such as hallucinations and misinformation. The AI chatbot serves a dual purpose: it enables students to access accurate, ondemand academic support and assists educators in the rapid creation of relevant educational materials. This dual functionality promotes learner autonomy and streamlines the instructional design process. The study aims to evaluate the effectiveness, reliability, and perceived usability of RAG based chatbots in higher education, exploring their potential to enhance educational practices and outcomes as well as supporting the broader adoption of AI technologies in language specific educational contexts. Findings from this research are expected to contribute to the emerging field of AI driven education by demonstrating how intelligent systems can be effectively aligned with pedagogical goals."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.20941v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.20941v3", "physics": true, "shape": "dot", "size": 6, "title": "Multivariate Standardized Residuals for Conformal Prediction. arXiv:2507.20941v3 Announce Type: replace-cross \nAbstract: While split conformal prediction guarantees marginal coverage, approaching the stronger property of conditional coverage is essential for reliable uncertainty quantification. Naive conformal scores, however, suffer from poor conditional coverage in heteroskedastic settings. In univariate regression, this is commonly addressed by normalizing nonconformity scores using estimated local score variance. In this work, we propose a natural extension of this normalization to the multivariate setting, effectively whitening the residuals to decouple output correlations and standardize local variance. We demonstrate that using the Mahalanobis distance induced by a learned local covariance as a nonconformity score provides a closed-form, computationally efficient mechanism for capturing inter-output correlations and heteroskedasticity, avoiding the expensive sampling required by previous methods based on cumulative distribution functions. This structure unlocks several practical extensions, including the handling of missing output values, the refinement of conformal sets when partial information is revealed, and the construction of valid conformal sets for transformations of the output. Finally, we provide extensive empirical evidence on both synthetic and real-world datasets showing that our approach yields conformal sets that significantly improve upon the conditional coverage of existing multivariate baselines."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "label": "Anticipating Futures to Optimize Systems and Customer Relationships", "physics": true, "shape": "dot", "size": 72, "title": "Anticipating Futures to Optimize Systems and Customer Relationships (11 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v2", "physics": true, "shape": "dot", "size": 6, "title": "Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework. arXiv:2601.21844v2 Announce Type: replace \nAbstract: Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of forecasting models should be judged not by statistical accuracy (e.g., MAE, RMSE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting models in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of downstream inventory implications. Using a wide range of simulation scenarios, we show that improvements in accuracy metrics do not necessarily lead to better KPIs, and that models with similar error profiles can induce different cost-service trade-offs. We analyze these discrepancies to characterize how forecast performance affects inventory outcomes and derive guidance for model selection. Overall, the framework links demand forecasting and inventory management, shifting evaluation from predictive accuracy toward operational relevance in the automotive aftermarket and related domains. An open-source implementation of the software is available at https://github.com/caisr-hh/TruckParts-Demand-Inventory-Simulator/releases/tag/IDA_2026."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v1", "physics": true, "shape": "dot", "size": 6, "title": "Bridging Forecast Accuracy and Inventory KPIs: A Simulation-Based Software Framework. arXiv:2601.21844v1 Announce Type: new \nAbstract: Efficient management of spare parts inventory is crucial in the automotive aftermarket, where demand is highly intermittent and uncertainty drives substantial cost and service risks. Forecasting is therefore central, but the quality of a forecasting model should be judged not by statistical accuracy (e.g., MAE, RMSE, IAE) but rather by its impact on key operational performance indicators (KPIs), such as total cost and service level. Yet most existing work evaluates models exclusively using accuracy metrics, and the relationship between these metrics and operational KPIs remains poorly understood. To address this gap, we propose a decision-centric simulation software framework that enables systematic evaluation of forecasting model in realistic inventory management setting. The framework comprises: (i) a synthetic demand generator tailored to spare-parts demand characteristics, (ii) a flexible forecasting module that can host arbitrary predictive models, and (iii) an inventory control simulator that consumes the forecasts and computes operational KPIs. This closed-loop setup enables researchers to evaluate models not only in terms of statistical error but also in terms of their downstream implications for inventory decisions. Using a wide range of simulation scenarios, we show that improvements in conventional accuracy metrics do not necessarily translate into better operational performance, and that models with similar statistical error profiles can induce markedly different cost-service trade-offs. We analyze these discrepancies to characterize how specific aspects of forecast performance affect inventory outcomes and derive guidance for model selection. Overall, the framework operationalizes the link between demand forecasting and inventory management, shifting evaluation from purely predictive accuracy toward operational relevance in the automotive aftermarket and related domains."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01912v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01912v1", "physics": true, "shape": "dot", "size": 6, "title": "Reliable Real-Time Value at Risk Estimation via Quantile Regression Forest with Conformal Calibration. arXiv:2602.01912v1 Announce Type: cross \nAbstract: Rapidly evolving market conditions call for real-time risk monitoring, but its online estimation remains challenging. In this paper, we study the online estimation of one of the most widely used risk measures, Value at Risk (VaR). Its accurate and reliable estimation is essential for timely risk control and informed decision-making. We propose to use the quantile regression forest in the offline-simulation-online-estimation (OSOA) framework. Specifically, the quantile regression forest is trained offline to learn the relationship between the online VaR and risk factors, and real-time VaR estimates are then produced online by incorporating observed risk factors. To further ensure reliability, we develop a conformalized estimator that calibrates the online VaR estimates. To the best of our knowledge, we are the first to leverage conformal calibration to estimate real-time VaR reliably based on the OSOA formulation. Theoretical analysis establishes the consistency and coverage validity of the proposed estimators. Numerical experiments confirm the proposed method and demonstrate its effectiveness in practice."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00037v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00037v1", "physics": true, "shape": "dot", "size": 6, "title": "Bitcoin Price Prediction using Machine Learning and Combinatorial Fusion Analysis. arXiv:2602.00037v1 Announce Type: cross \nAbstract: In this work, we propose to apply a new model fusion and learning paradigm, known as Combinatorial Fusion Analysis (CFA), to the field of Bitcoin price prediction. Price prediction of financial product has always been a big topic in finance, as the successful prediction of the price can yield significant profit. Every machine learning model has its own strength and weakness, which hinders progress toward robustness. CFA has been used to enhance models by leveraging rank-score characteristic (RSC) function and cognitive diversity in the combination of a moderate set of diverse and relatively well-performed models. Our method utilizes both score and rank combinations as well as other weighted combination techniques. Key metrics such as RMSE and MAPE are used to evaluate our methodology performance. Our proposal presents a notable MAPE performance of 0.19\\%. The proposed method greatly improves upon individual model performance, as well as outperforms other Bitcoin price prediction models."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2502.08792v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2502.08792v3", "physics": true, "shape": "dot", "size": 6, "title": "Randomly Wrong Signals: Bayesian Auction Design with ML Predictions. arXiv:2502.08792v3 Announce Type: replace-cross \nAbstract: We study auction design when a seller relies on machine-learning predictions of bidders\u0027 valuations that may be unreliable. Motivated by modern ML systems that are often accurate but occasionally fail in a way that is essentially uninformative, we model predictions as randomly wrong: with high probability the signal equals the bidder\u0027s true value, and otherwise it is a hallucination independent of the value. We analyze revenue-maximizing auctions when the seller publicly reveals these signals. A central difficulty is that the resulting posterior belief combines a continuous distribution with a point mass at the signal, so standard Myerson techniques do not directly apply. We provide a tractable characterization of the optimal signal-revealing auction by providing a closed-form characterization of the appropriate ironed virtual values. This characterization yields simple and intuitive implications. With a single bidder, the optimal mechanism reduces to a posted-price policy with a small number of regimes: the seller ignores low signals, follows intermediate signals, caps moderately high signals, and may again follow very high signals. With multiple bidders, we show that a simple eager second-price auction with signal-dependent reserve prices performs nearly optimally in numerical experiments and substantially outperforms natural benchmarks that either ignore the signal or treat it as fully reliable."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.11604v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.11604v2", "physics": true, "shape": "dot", "size": 6, "title": "Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce. arXiv:2510.11604v2 Announce Type: replace \nAbstract: In online retail, customer acquisition typically incurs higher costs than customer retention, motivating firms to invest in churn analytics. However, many contemporary churn models operate as opaque black boxes, limiting insight into the determinants of attrition, the timing of retention opportunities, and the identification of high-risk customer segments. Accordingly, the emphasis should shift from prediction alone to the design of personalized retention strategies grounded in interpretable evidence. This study advances a three-component framework that integrates explainable AI to quantify feature contributions, survival analysis to model time-to-event churn risk, and RFM profiling to segment customers by transactional behaviour. In combination, these methods enable the attribution of churn drivers, estimation of intervention windows, and prioritization of segments for targeted actions, thereby supporting strategies that reduce attrition and strengthen customer loyalty."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2402.03379v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2402.03379v2", "physics": true, "shape": "dot", "size": 6, "title": "Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing. arXiv:2402.03379v2 Announce Type: replace-cross \nAbstract: Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1) the Entire Chain-Enhanced Network, which utilizes user behavior patterns to estimate ITE throughout the entire chain space, models the various impacts of treatments on each task, and integrates task prior information to enhance context awareness across all stages, capturing the impact of treatment on different tasks, and 2) the Treatment-Enhanced Network, which facilitates fine-grained treatment modeling through bit-level feature interactions, thereby enabling adaptive feature adjustment. Extensive experiments on public and industrial datasets validate ECUPs effectiveness. Moreover, ECUP has been deployed on the Meituan food delivery platform, serving millions of daily active users, with the related dataset released for future research."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01410v4", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01410v4", "physics": true, "shape": "dot", "size": 6, "title": "Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems. arXiv:2601.01410v4 Announce Type: replace-cross \nAbstract: Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics can mask this operational asymmetry. We introduce an operator-legible evaluation framework -- Under-Prediction Rate (UPR), tail Reserve$_{99.5}^{\\%}$ requirements, and explicit inflation diagnostics (Bias$_{24h}$/OPR) -- to quantify one-sided reliability risk beyond MAPE.\n  Using this framework, we evaluate state space models (Mamba variants) and strong baselines on a weather-aligned California Independent System Operator (CAISO) dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 regional transmission areas) under a rolling-origin walk-forward backtest. We develop and evaluate thermal-lag-aligned weather fusion strategies for these architectures.\n  Our results demonstrate that standard accuracy metrics are insufficient proxies for operational safety: models with comparable MAPE can imply materially different tail reserve requirements (Reserve$_{99.5}^{\\%}$). We show that explicit weather integration narrows error distributions, reducing the impact of temperature-driven demand spikes. Furthermore, while probabilistic calibration reduces large-error events, it can induce systematic schedule inflation. We introduce Bias/OPR-constrained objectives to enable auditable trade-offs between minimizing tail risk and preventing trivial over-forecasting."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20932v2", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20932v2", "physics": true, "shape": "dot", "size": 6, "title": "Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy. arXiv:2512.20932v2 Announce Type: replace-cross \nAbstract: This paper presents a marketing analytics framework that operationalizes subscription pricing as a dynamic, guardrailed decision system, uniting multivariate demand forecasting, segment-level price elasticity, and churn propensity to optimize revenue, margin, and retention. The approach blends seasonal time-series models with tree-based learners, runs Monte Carlo scenario tests to map risk envelopes, and solves a constrained optimization that enforces business guardrails on customer experience, margin floors, and allowable churn. Validated across heterogeneous SaaS portfolios, the method consistently outperforms static tiers and uniform uplifts by reallocating price moves toward segments with higher willingness-to-pay while protecting price-sensitive cohorts. The system is designed for real-time recalibration via modular APIs and includes model explainability for governance and compliance. Managerially, the framework functions as a strategy playbook that clarifies when to shift from flat to dynamic pricing, how to align pricing with CLV and MRR targets, and how to embed ethical guardrails, enabling durable growth without eroding customer trust."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14663v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14663v1", "physics": true, "shape": "dot", "size": 6, "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets. arXiv:2601.14663v1 Announce Type: cross \nAbstract: Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty."}]);
                  edges = new vis.DataSet([{"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ooredoos-syntys-acquires-two-data-centers-in-qatar/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/att-occupied-data-center-up-for-sale-in-alpharetta-georgia/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-cfo-says-company-ended-2025-with-19gw-of-compute-scaled-revenue-at-same-speed/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/fuelcell-energy-partners-with-sdc-to-deploy-up-to-450mw-of-fuel-cells-across-data-centers-globally/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-launches-cloud-region-in-bangkok-thailand/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/openai-pledges-to-pay-its-own-way-to-power-stargate-data-centers/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/planned-project-atlas-data-center-campus-in-coweta-oklahoma-fails-to-secure-backing-from-planners/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/gpuaas-provider-voltage-park-merges-with-cloud-platform-lightning-ai/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vivopower-acquires-rights-to-25mw-data-center-in-uae/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cleanarc-partners-with-crow-holdings-for-245mw-campus-in-dallas-texas/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/videos/dcdstudio-enabling-liquid-cooling-through-open-cdus-with-abishek-gupta-nvent/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/norways-asp-acquires-land-for-25mw-data-center-project-in-suldal/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/g42-ceo-says-company-will-receive-first-ai-chip-shipments-within-months-to-support-initial-200mw-of-capacity-for-planned-stargate-cluster/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microgeo-satellite-operator-swissto12-secures-73m-in-funding/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/goodman-files-to-develop-90mw-data-center-campus-in-sydney-australia-2/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/upcloud-launches-data-center-region-in-norway/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/big-fiber-bypasses-tapped-out-bay-area-networks-with-dark-fiber-expansion/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/product-news/inside-nibi-how-immersion-cooling-and-ai-scale-compute-are-changing-canadian-hpc/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/the-biggest-data-center-stories-of-2025/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/whitepapers/powering-the-future-of-us-data-centers/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/google-behind-1bn-data-center-in-little-rock-arkansas-report/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/anger-over-plans-for-data-center-at-truman-brewery-in-londons-brick-lane/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/digital-halo-secures-469m-in-financing-for-philippines-data-center-project/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/analysis/2025-telco-talking-points-ai-fiber-frenzy-and-an-ma-boom/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/furiosaai-seeking-a-500m-funding-round-ahead-of-anticipated-ipo-report/", "smooth": false, "to": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "#ff9500", "dashes": true, "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "collapsed_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/meta-signs-176mwdc-solar-ppa-with-zelestra-in-texas/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tiktok-us-spin-off-finalized-led-by-oracle-silver-lake-and-mgx/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/airbus-bids-to-standardize-5g-network-services-with-upnext-spaceran-system/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/globalwafers-planning-to-further-expand-capacity-at-its-35bn-fab-in-sherman-texas/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/first-of-its-kind-50mw-smr-powered-data-center-planned-in-uzbekistan/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/kazakhstan-plans-data-center-valley-powered-by-coal/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/leeds-uk-based-photonic-chip-startup-optalysys-raises-23m/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/eu-outlines-plans-to-phase-out-high-risk-vendors-in-network-infrastructure/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/dayone-targets-560mw-data-center-campus-outside-helsinki-finland/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/japans-i-net-opens-data-center-in-yokohama/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bytedance-ramps-up-cloud-computing-offering-in-china/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/bouygue/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/e/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/microsoft-wins-170m-cloud-contract-from-us-air-force/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/global-switch-signs-eight-year-ppa-with-rwe-to-power-docklands-data-center-in-london/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/humain-and-infra-set-up-12bn-financing-package-to-fund-250mw-of-data-center-space-in-saudi-arabia/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.6)", "from": "cluster_80e99598-04cd-43cf-b7e2-a30e7a388b7b", "smooth": false, "to": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/telenor-sells-30-percent-stake-in-thailands-true-corporation-to-arise-digital-technology/", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11776v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11778v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11801v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 0.3)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11854v1", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11868v1", "value": 0.661817568428557, "width": 1}, {"color": "rgba(14, 17, 23, 0.3)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11854v1", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12061v1", "value": 0.6615066371103052, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11854v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11859v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11863v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11868v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11895v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11907v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11913v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11920v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11956v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11960v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11969v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11977v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11995v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12019v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12042v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12049v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12053v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12055v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12061v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12068v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12082v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12099v1", "smooth": false, "to": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "#ff9500", "dashes": true, "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "collapsed_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.15098v3", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18252v1", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17062v1", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17587v1", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13964v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13809v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13704v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13599v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.13563v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12946v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12805v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12534v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12467v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12415v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12276v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.09117v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08223v3", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06196v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06052v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04854v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.04339v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01129v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01090v2", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20905v4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "cluster_53887f68-8186-4fe1-8bf8-781fd8eaf86d", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20260v4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.09858v3", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01317v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00091v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.16049v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.23487v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22667v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22449v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/opinions/why-telcos-betting-on-full-automation-could-miss-the-real-ai-opportunity/", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06129v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v2", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v1", "value": 0.9998165254036124, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2505.05029v3", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2504.16743v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21993v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21016v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14295v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20100v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20487v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.19062v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17303v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11893v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.08005v2", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14982v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.11598v1", "smooth": false, "to": "cluster_8f4aa704-87f7-4396-8dfb-94f3834de620", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/vodafone-to-connect-crete-and-greece-with-new-subsea-cable/", "smooth": false, "to": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cable-theft-leaves-2500-properties-in-lincolnshire-uk-with-no-internet/", "smooth": false, "to": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/indigo-west-subsea-cable-undergoing-repairs/", "smooth": false, "to": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/splang/", "smooth": false, "to": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oms-taps-ulstein-for-two-new-subsea-cable-vessels/", "smooth": false, "to": "cluster_4bf62ccf-5777-42c2-9543-42b7e22196a4", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.01734v2", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2501.07809v2", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01071v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00057v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01131v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22970v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22880v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22865v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22409v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22400v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20174v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.21288v3", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18264v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17090v1", "smooth": false, "to": "cluster_e19eec8a-123a-42dd-8a1c-86886cb26cc6", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.13732v2", "smooth": false, "to": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2406.09260v3", "smooth": false, "to": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00184v1", "smooth": false, "to": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00153v1", "smooth": false, "to": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.12257v1", "smooth": false, "to": "cluster_48ba038a-3af8-4946-a419-03f7d081d9c5", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16336v2", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16327v2", "value": 0.8025141004654692, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16336v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16327v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.00521v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.08659v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.02158v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22419v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.22183v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2405.10377v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.23229v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.15824v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.20735v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.06188v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01832v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2506.06216v3", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.17028v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2511.09808v2", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.16855v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14476v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14784v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14485v1", "smooth": false, "to": "cluster_7430a38c-0954-4485-aa10-e8d27803d187", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.11883v2", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v2", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v1", "value": 0.9712480938325802, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v2", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00041v1", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v3", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v2", "value": 0.9822768994734185, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v3", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.15783v4", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.18785v1", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2509.17466v2", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14931v1", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14401v1", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14265v1", "smooth": false, "to": "cluster_265b2981-296c-4187-9134-e8e74d8247f8", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2507.20941v3", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v2", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v1", "value": 0.9925763896286037, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v2", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.01912v1", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.00037v1", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.21844v1", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2502.08792v3", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.11604v2", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2402.03379v2", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.01410v4", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2512.20932v2", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2601.14663v1", "smooth": false, "to": "cluster_7bac267a-159d-43ac-89f6-2e22e32dab71", "value": 0.9, "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"borderWidth": 0, "borderWidthSelected": 0, "chosen": {"node": false, "label": false}, "font": {"strokeWidth": 0}}, "interaction": {"hover": true, "hoverConnectedEdges": false, "selectConnectedEdges": false, "dragNodes": true, "dragView": true, "zoomView": true}, "physics": {"enabled": true, "stabilization": {"enabled": true, "iterations": 200, "updateInterval": 25, "fit": true}, "barnesHut": {"gravitationalConstant": -8000, "centralGravity": 0.3, "springLength": 150, "springConstant": 0.04, "damping": 0.09, "avoidOverlap": 0.5}, "solver": "barnesHut"}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    
    <script type="text/javascript">
        var selectedNode = null;
        var physicsDisabled = false;
        
        // Disable physics after stabilization so nodes stay where moved
        network.once("stabilizationIterationsDone", function() {
            network.setOptions({ physics: { enabled: false } });
            physicsDisabled = true;
        });
        
        // When dragging a cluster node, move all connected signal nodes with it
        var dragStartPositions = {};
        var clusterStartPosition = {};
        var isDraggingCluster = false;
        
        network.on("dragStart", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                
                // Check if this is a cluster node
                if (nodeId.startsWith('cluster_')) {
                    isDraggingCluster = true;
                    // Store initial position of cluster
                    clusterStartPosition = network.getPositions([nodeId])[nodeId];
                    
                    // Get all connected signal nodes
                    var connectedNodes = network.getConnectedNodes(nodeId);
                    dragStartPositions = {};
                    
                    connectedNodes.forEach(function(connectedId) {
                        if (!connectedId.startsWith('cluster_')) {
                            dragStartPositions[connectedId] = network.getPositions([connectedId])[connectedId];
                        }
                    });
                } else {
                    // Dragging a signal node - allow independent movement
                    isDraggingCluster = false;
                }
            }
        });
        
        network.on("dragging", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                
                // If dragging a cluster, move connected signals
                if (isDraggingCluster && nodeId.startsWith('cluster_') && Object.keys(dragStartPositions).length > 0) {
                    var currentPos = network.getPositions([nodeId])[nodeId];
                    var dx = currentPos.x - clusterStartPosition.x;
                    var dy = currentPos.y - clusterStartPosition.y;
                    
                    // Move all connected signal nodes by the same offset
                    for (var connectedId in dragStartPositions) {
                        var oldPos = dragStartPositions[connectedId];
                        var newX = oldPos.x + dx;
                        var newY = oldPos.y + dy;
                        network.moveNode(connectedId, newX, newY);
                    }
                }
                // If dragging a signal node, it moves independently (default behavior)
            }
        });
        
        network.on("dragEnd", function(params) {
            // Clear drag state
            dragStartPositions = {};
            clusterStartPosition = {};
            isDraggingCluster = false;
        });
        
        network.on("click", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                var node = network.body.data.nodes.get(nodeId);
                
                // Create persistent popup
                var popup = document.createElement('div');
                popup.id = 'node-popup';
                popup.style.position = 'fixed';
                popup.style.background = '#1e1e1e';
                popup.style.color = 'white';
                popup.style.padding = '15px';
                popup.style.borderRadius = '8px';
                popup.style.maxWidth = '400px';
                popup.style.border = '2px solid #f4b000';
                popup.style.zIndex = '10000';
                popup.style.top = '50%';
                popup.style.left = '50%';
                popup.style.transform = 'translate(-50%, -50%)';
                popup.style.boxShadow = '0 4px 20px rgba(0,0,0,0.5)';
                popup.innerHTML = '<strong>' + (node.label || 'Signal') + '</strong><br><br>' + 
                                 (node.title || 'No content') + 
                                 '<br><br><small style="color: #888;">Click anywhere to close</small>';
                
                // Remove existing popup if any
                var existing = document.getElementById('node-popup');
                if (existing) existing.remove();
                
                document.body.appendChild(popup);
                selectedNode = nodeId;
            } else {
                // Click on empty space - remove popup
                var popup = document.getElementById('node-popup');
                if (popup) popup.remove();
                selectedNode = null;
            }
        });
    </script>
    </body>
</html>