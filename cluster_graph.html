<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 600px;
                 background-color: #0e1117;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/inferencemax-open-source-inference", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/inferencemax-open-source-inference", "physics": true, "shape": "dot", "size": 6, "title": "InferenceMAX\u2122: Open Source Inference Benchmarking. NVIDIA GB200 NVL72, AMD MI355X, Throughput Token per GPU, Latency Tok/s/user, Perf per Dollar, Tokens per Provisioned Megawatt, DeepSeek R1 670B, GPTOSS 120B, Llama3 70B"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "label": "AI Gets Smarter Through Smarter Problem Solving and Reasoning", "physics": true, "shape": "dot", "size": 120, "title": "AI Gets Smarter Through Smarter Problem Solving and Reasoning (290 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04184v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04184v1", "physics": true, "shape": "dot", "size": 6, "title": "Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models. arXiv:2602.04184v1 Announce Type: cross \nAbstract: Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-world dataset linking free-form instructions (with referentiality) to nuScenes ground-truth motion, enables instruction-conditioned planning. In this work, we adapt OpenEMMA, an open-source MLLM-based end-to-end driving framework that ingests front-camera views and ego-state and outputs 10-step speed-curvature trajectories, to this setting, presenting a reproducible instruction-conditioned baseline on doScenes and investigate the effects of human instruction prompts on predicted driving behavior. We integrate doScenes directives as passenger-style prompts within OpenEMMA\u0027s vision-language interface, enabling linguistic conditioning before trajectory generation. Evaluated on 849 annotated scenes using ADE, we observe that instruction conditioning substantially improves robustness by preventing extreme baseline failures, yielding a 98.7% reduction in mean ADE. When such outliers are removed, instructions still influence trajectory alignment, with well-phrased prompts improving ADE by up to 5.1%. We use this analysis to discuss what makes a \"good\" instruction for the OpenEMMA framework. We release the evaluation prompts and scripts to establish a reproducible baseline for instruction-aware planning. GitHub: https://github.com/Mi3-Lab/doScenes-VLM-Planning"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04256v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04256v1", "physics": true, "shape": "dot", "size": 6, "title": "AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models. arXiv:2602.04256v1 Announce Type: cross \nAbstract: End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of end-to-end driving models in diverse and unseen scenarios. However, existing VLM-based approaches still face challenges, including suboptimal lane perception, language understanding biases, and difficulties in handling corner cases. To address these issues, we propose AppleVLM, an advanced perception and planning-enhanced VLM model for robust end-to-end driving. AppleVLM introduces a novel vision encoder and a planning strategy encoder to improve perception and decision-making. Firstly, the vision encoder fuses spatial-temporal information from multi-view images across multiple timesteps using a deformable transformer mechanism, enhancing robustness to camera variations and facilitating scalable deployment across different vehicle platforms. Secondly, unlike traditional VLM-based approaches, AppleVLM introduces a dedicated planning modality that encodes explicit Bird\u0027s-Eye-View spatial information, mitigating language biases in navigation instructions. Finally, a VLM decoder fine-tuned by a hierarchical Chain-of-Thought integrates vision, language, and planning features to output robust driving waypoints. We evaluate AppleVLM in closed-loop experiments on two CARLA benchmarks, achieving state-of-the-art driving performance. Furthermore, we deploy AppleVLM on an AGV platform and successfully showcase real-world end-to-end autonomous driving in complex outdoor environments."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04197v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04197v1", "physics": true, "shape": "dot", "size": 6, "title": "From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents. arXiv:2602.04197v1 Announce Type: cross \nAbstract: The enhanced capabilities of LLM-based agents come with an emergency for model planning and tool-use abilities. Attributing to helpful-harmless trade-off from LLM alignment, agents typically also inherit the flaw of \"over-refusal\", which is a passive failure mode. However, the proactive planning and action capabilities of agents introduce another crucial danger on the other side of the trade-off. This phenomenon we term \"Toxic Proactivity\u0027\u0027: an active failure mode in which an agent, driven by the optimization for Machiavellian helpfulness, disregards ethical constraints to maximize utility. Unlike over-refusal, Toxic Proactivity manifests as the agent taking excessive or manipulative measures to ensure its \"usefulness\u0027\u0027 is maintained. Existing research pays little attention to identifying this behavior, as it often lacks the subtle context required for such strategies to unfold. To reveal this risk, we introduce a novel evaluation framework based on dilemma-driven interactions between dual models, enabling the simulation and analysis of agent behavior over multi-step behavioral trajectories. Through extensive experiments with mainstream LLMs, we demonstrate that Toxic Proactivity is a widespread behavioral phenomenon and reveal two major tendencies. We further present a systematic benchmark for evaluating Toxic Proactive behavior across contextual settings."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04206v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04206v1", "physics": true, "shape": "dot", "size": 6, "title": "Enforcing Monotonic Progress in Legal Cross-Examination: Preventing Long-Horizon Stagnation in LLM-Based Inquiry. arXiv:2602.04206v1 Announce Type: cross \nAbstract: Large language models (LLMs) exhibit impressive linguistic fluency but struggle to reliably complete long-horizon tasks under explicit procedural constraints. In legal cross-examination, purely proba-bilistic generation often maintains behavioral coherence while failing to ensure procedural advancement. We characterize this failure as procedural stagnation and propose Soft-FSM, a neuro-symbolic architecture that enforces monotonic progress over accumulated Key Information Units (KIUs) via an external deterministic state controller. Experiments on three real-world Taiwanese criminal homicide cases show that baseline methods collapse below 40% completeness, while Soft-FSM consistently achieves over 97% with near-zero redundancy. These results suggest that, in such domains, reliable task completion cannot be guaranteed by emergent LLM behavior alone, and can be reliably enforced through explicit and verifiable external state control."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04208v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04208v1", "physics": true, "shape": "dot", "size": 6, "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models. arXiv:2602.04208v1 Announce Type: cross \nAbstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity, where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on \u0027self-uncertainty\u0027, inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04212v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04212v1", "physics": true, "shape": "dot", "size": 6, "title": "Language Models Struggle to Use Representations Learned In-Context. arXiv:2602.04212v1 Announce Type: cross \nAbstract: Though large language models (LLMs) have enabled great success across a wide variety of tasks, they still appear to fall short of one of the loftier goals of artificial intelligence research: creating an artificial system that can adapt its behavior to radically new contexts upon deployment. One important step towards this goal is to create systems that can induce rich representations of data that are seen in-context, and then flexibly deploy these representations to accomplish goals. Recently, Park et al. (2024) demonstrated that current LLMs are indeed capable of inducing such representation from context (i.e., in-context representation learning). The present study investigates whether LLMs can use these representations to complete simple downstream tasks.\n  We first assess whether open-weights LLMs can use in-context representations for next-token prediction, and then probe models using a novel task, adaptive world modeling. In both tasks, we find evidence that open-weights LLMs struggle to deploy representations of novel semantics that are defined in-context, even if they encode these semantics in their latent representations. Furthermore, we assess closed-source, state-of-the-art reasoning models on the adaptive world modeling task, demonstrating that even the most performant LLMs cannot reliably leverage novel patterns presented in-context. Overall, this work seeks to inspire novel methods for encouraging models to not only encode information presented in-context, but to do so in a manner that supports flexible deployment of this information."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04215v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04215v1", "physics": true, "shape": "dot", "size": 6, "title": "OAT: Ordered Action Tokenization. arXiv:2602.04215v1 Announce Type: cross \nAbstract: Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04224v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04224v1", "physics": true, "shape": "dot", "size": 6, "title": "RAPO: Risk-Aware Preference Optimization for Generalizable Safe Reasoning. arXiv:2602.04224v1 Announce Type: cross \nAbstract: Large Reasoning Models (LRMs) have achieved tremendous success with their chain-of-thought (CoT) reasoning, yet also face safety issues similar to those of basic language models. In particular, while algorithms are designed to guide them to deliberately refuse harmful prompts with safe reasoning, this process often fails to generalize against diverse and complex jailbreak attacks. In this work, we attribute these failures to the generalization of the safe reasoning process, particularly their insufficiency against complex attack prompts. We provide both theoretical and empirical evidence to show the necessity of a more sufficient safe reasoning process to defend against advanced attack prompts. Building on this insight, we propose a Risk-Aware Preference Optimization (RAPO) framework that enables LRM to adaptively identify and address the safety risks with appropriate granularity in its thinking content. Extensive experiments demonstrate that RAPO successfully generalizes multiple LRMs\u0027 safe reasoning adaptively across diverse attack prompts whilst preserving general utility, contributing a robust alignment technique for LRM safety. Our code is available at https://github.com/weizeming/RAPO."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04252v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04252v1", "physics": true, "shape": "dot", "size": 6, "title": "ACIL: Active Class Incremental Learning for Image Classification. arXiv:2602.04252v1 Announce Type: cross \nAbstract: Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focused on avoiding catastrophic forgetting, which occurs due to the continuously changing class distributions in each episode and the inaccessibility of the data from previous episodes. However, these methods assume that all the training samples in every episode are annotated; this not only incurs a huge annotation cost, but also results in a wastage of annotation effort, since most of the samples in a given episode will not be accessible to the model in subsequent episodes. Active learning algorithms identify the salient and informative samples from large amounts of unlabeled data and are instrumental in reducing the human annotation effort in inducing a deep neural network. In this paper, we propose ACIL, a novel active learning framework for class incremental learning settings. We exploit a criterion based on uncertainty and diversity to identify the exemplar samples that need to be annotated in each episode, and will be appended to the data in the next episode. Such a framework can drastically reduce annotation cost and can also avoid catastrophic forgetting. Our extensive empirical analyses on several vision datasets corroborate the promise and potential of our framework against relevant baselines."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04265v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04265v1", "physics": true, "shape": "dot", "size": 6, "title": "Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning. arXiv:2602.04265v1 Announce Type: cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, existing reward schemes fail to distinguish between the need for extensive search during problem-solving and the efficiency required for mastered knowledge. In this work, we introduce T2T(Thickening-to-Thinning), a dynamic reward framework inspired by human learning processes. Specifically, it implements a dual-phase mechanism: (1) On incorrect attempts, T2T incentivizes \"thickening\" (longer trajectories) to broaden the search space and explore novel solution paths; (2) Upon achieving correctness, it shifts to \"thinning\", imposing length penalties to discourage redundancy, thereby fostering model confidence and crystallizing reasoning capabilities. Extensive experiments on mathematical benchmarks (MATH-500, AIME, AMC) across Qwen-series and Deepseek models demonstrate that T2T significantly outperforms standard GRPO and recent baselines, achieving superior performance."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04288v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04288v1", "physics": true, "shape": "dot", "size": 6, "title": "Contextual Drag: How Errors in the Context Affect LLM Reasoning. arXiv:2602.04288v1 Announce Type: cross \nAbstract: Central to many self-improvement pipelines for large language models (LLMs) is the assumption that models can improve by reflecting on past mistakes. We study a phenomenon termed contextual drag: the presence of failed attempts in the context biases subsequent generations toward structurally similar errors. Across evaluations of 11 proprietary and open-weight models on 8 reasoning tasks, contextual drag induces 10-20% performance drops, and iterative self-refinement in models with severe contextual drag can collapse into self-deterioration. Structural analysis using tree edit distance reveals that subsequent reasoning trajectories inherit structurally similar error patterns from the context. We demonstrate that neither external feedback nor successful self-verification suffices to eliminate this effect. While mitigation strategies such as fallback-behavior fine-tuning and context denoising yield partial improvements, they fail to fully restore baseline performance, positioning contextual drag as a persistent failure mode in current reasoning architectures."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04291v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04291v1", "physics": true, "shape": "dot", "size": 6, "title": "Disentangling Causal Importance from Emergent Structure in Multi-Expert Orchestration. arXiv:2602.04291v1 Announce Type: cross \nAbstract: Multi-expert systems, where multiple Large Language Models (LLMs) collaborate to solve complex tasks, are increasingly adopted for high-performance reasoning and generation. However, the orchestration policies governing expert interaction and sequencing remain largely opaque. We introduce INFORM, an interpretability analysis that treats orchestration as an explicit, analyzable computation, enabling the decoupling of expert interaction structure, execution order, and causal attribution. We use INFORM to evaluate an orchestrator on GSM8K, HumanEval, and MMLU using a homogeneous consortium of ten instruction-tuned experts drawn from LLaMA-3.1 8B, Qwen-3 8B, and DeepSeek-R1 8B, with controlled decoding-temperature variation, and a secondary heterogeneous consortium spanning 1B-7B parameter models. Across tasks, routing dominance is a poor proxy for functional necessity. We reveal a divergence between relational importance, captured by routing mass and interaction topology, and intrinsic importance, measured via gradient-based causal attribution: frequently selected experts often act as interaction hubs with limited causal influence, while sparsely routed experts can be structurally critical. Orchestration behaviors emerge asynchronously, with expert centralization preceding stable routing confidence and expert ordering remaining non-deterministic. Targeted ablations show that masking intrinsically important experts induces disproportionate collapse in interaction structure compared to masking frequent peers, confirming that INFORM exposes causal and structural dependencies beyond accuracy metrics alone."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04296v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04296v1", "physics": true, "shape": "dot", "size": 6, "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas. arXiv:2602.04296v1 Announce Type: cross \nAbstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04297v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04297v1", "physics": true, "shape": "dot", "size": 6, "title": "Revisiting Prompt Sensitivity in Large Language Models for Text Classification: The Role of Prompt Underspecification. arXiv:2602.04297v1 Announce Type: cross \nAbstract: Large language models (LLMs) are widely used as zero-shot and few-shot classifiers, where task behaviour is largely controlled through prompting. A growing number of works have observed that LLMs are sensitive to prompt variations, with small changes leading to large changes in performance. However, in many cases, the investigation of sensitivity is performed using underspecified prompts that provide minimal task instructions and weakly constrain the model\u0027s output space. In this work, we argue that a significant portion of the observed prompt sensitivity can be attributed to prompt underspecification. We systematically study and compare the sensitivity of underspecified prompts and prompts that provide specific instructions. Utilising performance analysis, logit analysis, and linear probing, we find that underspecified prompts exhibit higher performance variance and lower logit values for relevant tokens, while instruction-prompts suffer less from such problems. However, linear probing analysis suggests that the effects of prompt underspecification have only a marginal impact on the internal LLM representations, instead emerging in the final layers. Overall, our findings highlight the need for more rigour when investigating and mitigating prompt sensitivity."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04304v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04304v1", "physics": true, "shape": "dot", "size": 6, "title": "Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement. arXiv:2602.04304v1 Announce Type: cross \nAbstract: Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static \"magic layer\" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04306v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04306v1", "physics": true, "shape": "dot", "size": 6, "title": "DeFrame: Debiasing Large Language Models Against Framing Effects. arXiv:2602.04306v1 Announce Type: cross \nAbstract: As large language models (LLMs) are increasingly deployed in real-world applications, ensuring their fair responses across demographics has become crucial. Despite many efforts, an ongoing challenge is hidden bias: LLMs appear fair under standard evaluations, but can produce biased responses outside those evaluation settings. In this paper, we identify framing -- differences in how semantically equivalent prompts are expressed (e.g., \"A is better than B\" vs. \"B is worse than A\") -- as an underexplored contributor to this gap. We first introduce the concept of \"framing disparity\" to quantify the impact of framing on fairness evaluation. By augmenting fairness evaluation benchmarks with alternative framings, we find that (1) fairness scores vary significantly with framing and (2) existing debiasing methods improve overall (i.e., frame-averaged) fairness, but often fail to reduce framing-induced disparities. To address this, we propose a framing-aware debiasing method that encourages LLMs to be more consistent across framings. Experiments demonstrate that our approach reduces overall bias and improves robustness against framing disparities, enabling LLMs to produce fairer and more consistent responses."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04398v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04398v1", "physics": true, "shape": "dot", "size": 6, "title": "Bi-directional Bias Attribution: Debiasing Large Language Models without Modifying Prompts. arXiv:2602.04398v1 Announce Type: cross \nAbstract: Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks. However, their outputs often exhibit social biases, raising fairness concerns. Existing debiasing methods, such as fine-tuning on additional datasets or prompt engineering, face scalability issues or compromise user experience in multi-turn interactions. To address these challenges, we propose a framework for detecting stereotype-inducing words and attributing neuron-level bias in LLMs, without the need for fine-tuning or prompt modification. Our framework first identifies stereotype-inducing adjectives and nouns via comparative analysis across demographic groups. We then attribute biased behavior to specific neurons using two attribution strategies based on integrated gradients. Finally, we mitigate bias by directly intervening on their activations at the projection layer. Experiments on three widely used LLMs demonstrate that our method effectively reduces bias while preserving overall model performance. Code is available at the github link: https://github.com/XMUDeepLIT/Bi-directional-Bias-Attribution."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04337v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04337v1", "physics": true, "shape": "dot", "size": 6, "title": "Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner. arXiv:2602.04337v1 Announce Type: cross \nAbstract: Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04340v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04340v1", "physics": true, "shape": "dot", "size": 6, "title": "Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning. arXiv:2602.04340v1 Announce Type: cross \nAbstract: Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04344v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04344v1", "physics": true, "shape": "dot", "size": 6, "title": "UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching. arXiv:2602.04344v1 Announce Type: cross \nAbstract: Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their iterative and non-autoregressive generation process. To leverage this, we propose UnMaskFork (UMF), a framework that formulates the unmasking trajectory as a search tree and employs Monte Carlo Tree Search to optimize the generation path. In contrast to standard scaling methods relying on stochastic sampling, UMF explores the search space through deterministic partial unmasking actions performed by multiple MDLMs. Our empirical evaluation demonstrates that UMF consistently outperforms existing test-time scaling baselines on complex coding benchmarks, while also exhibiting strong scalability on mathematical reasoning tasks."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04360v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04360v1", "physics": true, "shape": "dot", "size": 6, "title": "Counterfactual Explanations for Hypergraph Neural Networks. arXiv:2602.04360v1 Announce Type: cross \nAbstract: Hypergraph neural networks (HGNNs) effectively model higher-order interactions in many real-world systems but remain difficult to interpret, limiting their deployment in high-stakes settings.\n  We introduce CF-HyperGNNExplainer, a counterfactual explanation method for HGNNs that identifies the minimal structural changes required to alter a model\u0027s prediction. The method generates counterfactual hypergraphs using actionable edits limited to removing node-hyperedge incidences or deleting hyperedges, producing concise and structurally meaningful explanations. Experiments on three benchmark datasets show that CF-HyperGNNExplainer generates valid and concise counterfactuals, highlighting the higher-order relations most critical to HGNN decisions."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04361v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04361v1", "physics": true, "shape": "dot", "size": 6, "title": "SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration. arXiv:2602.04361v1 Announce Type: cross \nAbstract: Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of attention increases quartically with resolution, causing substantial latency. Prior accelerations often skip high-resolution scales, which speeds up inference but discards high-frequency details and harms image quality. To address these problems, we present SparVAR, a training-free acceleration framework that exploits three properties of VAR attention: (i) strong attention sinks, (ii) cross-scale activation similarity, and (iii) pronounced locality. Specifically, we dynamically predict the sparse attention pattern of later high-resolution scales from a sparse decision scale, and construct scale self-similar sparse attention via an efficient index-mapping mechanism, enabling high-efficiency sparse attention computation at large scales. Furthermore, we propose cross-scale local sparse attention and implement an efficient block-wise sparse kernel, which achieves $\\mathbf{\u003e 5\\times}$ faster forward speed than FlashAttention. Extensive experiments demonstrate that the proposed SparseVAR can reduce the generation time of an 8B model producing $1024\\times1024$ high-resolution images to the 1s, without skipping the last scales. Compared with the VAR baseline accelerated by FlashAttention, our method achieves a $\\mathbf{1.57\\times}$ speed-up while preserving almost all high-frequency details. When combined with existing scale-skipping strategies, SparseVAR attains up to a $\\mathbf{2.28\\times}$ acceleration, while maintaining competitive visual generation quality. Code is available at https://github.com/CAS-CLab/SparVAR."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04380v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04380v1", "physics": true, "shape": "dot", "size": 6, "title": "Beyond KL Divergence: Policy Optimization with Flexible Bregman Divergences for LLM Reasoning. arXiv:2602.04380v1 Announce Type: cross \nAbstract: Policy optimization methods like Group Relative Policy Optimization (GRPO) and its variants have achieved strong results on mathematical reasoning and code generation tasks. Despite extensive exploration of reward processing strategies and training dynamics, all existing group-based methods exclusively use KL divergence for policy regularization, leaving the choice of divergence function unexplored. We introduce Group-Based Mirror Policy Optimization (GBMPO), a framework that extends group-based policy optimization to flexible Bregman divergences, including hand-designed alternatives (L2 in probability space) and learned neural mirror maps. On GSM8K mathematical reasoning, hand-designed ProbL2-GRPO achieves 86.7% accuracy, improving +5.5 points over the Dr. GRPO baseline. On MBPP code generation, neural mirror maps reach 60.1-60.8% pass@1, with random initialization already capturing most of the benefit. While evolutionary strategies meta-learning provides marginal accuracy improvements, its primary value lies in variance reduction ($\\pm$0.2 versus $\\pm$0.6) and efficiency gains (15% shorter responses on MBPP), suggesting that random initialization of neural mirror maps is sufficient for most practical applications. These results establish divergence choice as a critical, previously unexplored design dimension in group-based policy optimization for LLM reasoning."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04396v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04396v1", "physics": true, "shape": "dot", "size": 6, "title": "LoRDO: Distributed Low-Rank Optimization with Infrequent Communication. arXiv:2602.04396v1 Announce Type: cross \nAbstract: Distributed training of foundation models via $\\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate these constraints; however, in the local-update regime, workers lack access to the full-batch gradients required to compute low-rank projections, which degrades performance. We propose $\\texttt{LoRDO}$, a principled framework unifying low-rank optimization with infrequent synchronization. We first demonstrate that, while global projections based on pseudo-gradients are theoretically superior, they permanently restrict the optimization trajectory to a low-rank subspace. To restore subspace exploration, we introduce a full-rank quasi-hyperbolic update. $\\texttt{LoRDO}$ achieves near-parity with low-rank $\\texttt{DDP}$ in language modeling and downstream tasks at model scales of $125$M--$720$M, while reducing communication by $\\approx 10 \\times$. Finally, we show that $\\texttt{LoRDO}$ improves performance even more in very low-memory settings with small rank/batch size."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#ff9500", "font": {"color": "white"}, "id": "collapsed_36675d2d-fb7c-4981-a959-f17f2edd4531", "label": "+265 more", "physics": true, "shape": "box", "size": 12, "title": "This cluster has 265 more signals not shown in the graph.\nSelect the cluster below to view all 290 signals."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/californian-senator-proposes-bill-to-create-new-rate-class-for-large-load-data-centers/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/californian-senator-proposes-bill-to-create-new-rate-class-for-large-load-data-centers/", "physics": true, "shape": "dot", "size": 6, "title": "Californian Senator proposes bill to create new rate class for large load data centers. \u003cp\u003eWould apply to facilities with a capacity of 75MW or more\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "label": "AI\u0027s growing infrastructure demands reshape research and industry.", "physics": true, "shape": "dot", "size": 80, "title": "AI\u0027s growing infrastructure demands reshape research and industry. (20 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tennessee-utility-tva-projects-data-center-load-to-double-across-service-area-by-2030/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tennessee-utility-tva-projects-data-center-load-to-double-across-service-area-by-2030/", "physics": true, "shape": "dot", "size": 6, "title": "Tennessee utility TVA projects data center load to double across service area by 2030. \u003cp\u003eUtility aims to construct 6.2GW of new generation assets to meet increased demand\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/multi-gigawatt-data-center-campus-planned-in-east-texas/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/multi-gigawatt-data-center-campus-planned-in-east-texas/", "physics": true, "shape": "dot", "size": 6, "title": "Multi-gigawatt data center campus planned in East Texas. \u003cp\u003eFormer paper mill site in Lufkin targeted by Amp Energy\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tsmc-to-produce-3nm-ai-chips-at-second-fab-in-kumamoto-japan/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tsmc-to-produce-3nm-ai-chips-at-second-fab-in-kumamoto-japan/", "physics": true, "shape": "dot", "size": 6, "title": "TSMC to produce 3nm AI chips at second fab in Kumamoto, Japan. \u003cp\u003eReverses previous decision from the company to manufacture 7nm chips at the site\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/denmarks-thylander-secures-outside-investors-for-data-center-venture/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/denmarks-thylander-secures-outside-investors-for-data-center-venture/", "physics": true, "shape": "dot", "size": 6, "title": "Denmark\u2019s Thylander secures outside investors for data center venture. \u003cp\u003eCompany working on 100MW projects in Esbjerg\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/aws-has-never-retired-an-nvidia-a100-server-ceo-matt-garman-claims/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/aws-has-never-retired-an-nvidia-a100-server-ceo-matt-garman-claims/", "physics": true, "shape": "dot", "size": 6, "title": "AWS has \u201cnever retired\u201d an Nvidia A100 server, CEO Matt Garman claims. \u003cp\u003eDemand still high from those running HPC workloads\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/nvidia-prologis-epri-infrapartners-target-prefab-data-centers-at-substation-sites/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/nvidia-prologis-epri-infrapartners-target-prefab-data-centers-at-substation-sites/", "physics": true, "shape": "dot", "size": 6, "title": "Nvidia, Prologis, EPRI, InfraPartners target prefab data centers at substation sites. \u003cp\u003eFive pilot projects planned in US in 2026\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oracle-nabs-881m-cloud-contract-from-us-air-force/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oracle-nabs-881m-cloud-contract-from-us-air-force/", "physics": true, "shape": "dot", "size": 6, "title": "Oracle nabs $88.1m cloud contract from US Air Force. \u003cp\u003eThe latest contract issued under the Cloud One program\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ai-compute-company-subgen-ai-signs-cloud-agreement-with-alibaba-cloud-netherlands/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ai-compute-company-subgen-ai-signs-cloud-agreement-with-alibaba-cloud-netherlands/", "physics": true, "shape": "dot", "size": 6, "title": "AI compute company Subgen AI signs cloud agreement with Alibaba Cloud Netherlands. \u003cp\u003eWill give Subgen AI clients access to Alibaba\u0027s infrastructure and technologies\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power", "physics": true, "shape": "dot", "size": 6, "title": "How AI Labs Are Solving the Power Crisis: The Onsite Gas Deep Dive. Bring Your Own Generation, Sayonara Electric Grid, Turbines vs. Recips. vs. Fuel Cells, Why Not Build More CCGTs?, Onsite Power TCO"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/microsofts-ai-strategy-deconstructed", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/microsofts-ai-strategy-deconstructed", "physics": true, "shape": "dot", "size": 6, "title": "Microsoft\u0027s AI Strategy Deconstructed - From Energy to Tokens. \"The Big Pause\", AI Tokens Factory Economics Stack, OpenAI, Neocloud Renting, GitHub Copilot Woes, MAI and Maia Floundering"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/aws-trainium3-deep-dive-a-potential", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/aws-trainium3-deep-dive-a-potential", "physics": true, "shape": "dot", "size": 6, "title": "AWS Trainium3 Deep Dive | A Potential Challenger Approaching. NL72x2/NL32x2 Scale Up Rack Architecture, Step-Function Software \u0026 System Improvements, Optimized Perf per TCO, \u0026#8220;Amazon Basics\u0026#8221; GB200 NVL36x2, Astera Labs, Trainium4"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion", "physics": true, "shape": "dot", "size": 6, "title": "Amazon\u2019s AI Resurgence: AWS \u0026 Anthropic\u0027s Multi-Gigawatt Trainium Expansion. Anthropic multi-gigawatt clusters, Trainium ramp, best TCO per memory bandwidth, system-level roadmap, Bedrock and internal models"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the", "physics": true, "shape": "dot", "size": 6, "title": "TPUv7: Google Takes a Swing at the King. Anthropic\u0026#8217;s 1GW+ TPUs, New customers Meta/SSI/xAI/OAI, Full Stack Review of v7 Ironwood, CUDA Moat at risk, Next Generation TPUv8AX and TPUv8X versus Vera Rubin"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/xais-colossus-2-first-gigawatt-datacenter", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/xais-colossus-2-first-gigawatt-datacenter", "physics": true, "shape": "dot", "size": 6, "title": "xAI\u0027s Colossus 2 - First Gigawatt Datacenter In The World, Unique RL Methodology, Capital Raise. On Site Turbines, Mississippi Expansion, Solaris Energy, Can xAI afford it?, Middle East Funding, Tesla, Talent Exodus, API revenue, Consumer Growth, RL Environment"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/another-giant-leap-the-rubin-cpx-specialized-accelerator-rack", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/another-giant-leap-the-rubin-cpx-specialized-accelerator-rack", "physics": true, "shape": "dot", "size": 6, "title": "Another Giant Leap: The Rubin CPX Specialized Accelerator \u0026 Rack. New Prefill Specialized GPU, Rack Architecture, BOM, Disaggregated PD, Higher Perf per TCO, Lower TCO, GDDR7 \u0026 HBM Market Trends"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/huawei-ascend-production-ramp", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/huawei-ascend-production-ramp", "physics": true, "shape": "dot", "size": 6, "title": "Huawei Ascend Production Ramp: Die Banks, TSMC Continued Production, HBM is The Bottleneck. H20 Shipments, Blackwell B30A, Bottlenecks to Chinese Chip Production, Export Controls, CXMT, SMIC, Cambricon"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/h100-vs-gb200-nvl72-training-benchmarks", "label": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/h100-vs-gb200-nvl72-training-benchmarks", "physics": true, "shape": "dot", "size": 6, "title": "H100 vs GB200 NVL72 Training Benchmarks - Power, TCO, and Reliability Analysis, Software Improvement Over Time. Joules per Token, TCO Per Million Tokens, MFU, Tokens Per US Annual Household Energy Usage, DeepSeek 670B, GB200 Unreliability, Backplane Downtime"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.26275v3", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.26275v3", "physics": true, "shape": "dot", "size": 6, "title": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI. arXiv:2510.26275v3 Announce Type: replace-cross \nAbstract: Generative AI (GenAI) is rapidly transforming software engineering (SE) practices, influencing how SE processes are executed, as well as how software systems are developed, operated, and evolved. This paper applies design science research to build a roadmap for GenAI-augmented SE. The process consists of three cycles that incrementally integrate multiple sources of evidence, including collaborative discussions from the FSE 2025 \"Software Engineering 2030\" workshop, rapid literature reviews, and external feedback sessions involving peers. McLuhan\u0027s tetrads were used as a conceptual instrument to systematically capture the transforming effects of GenAI on SE processes and software products. The resulting roadmap identifies four fundamental forms of GenAI augmentation in SE and systematically characterizes their related research challenges and opportunities. These insights are then consolidated into a set of future research directions. By grounding the roadmap in a rigorous multi-cycle process and cross-validating it among independent author teams and peers, the study provides a transparent and reproducible foundation for analyzing how GenAI affects SE processes, methods and tools, and for framing future research within this rapidly evolving area."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.03969v1", "label": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.03969v1", "physics": true, "shape": "dot", "size": 6, "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem. arXiv:2602.03969v1 Announce Type: cross \nAbstract: The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration."}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/government-of-mali-launches-data-center-in-bamako/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/government-of-mali-launches-data-center-in-bamako/", "physics": true, "shape": "dot", "size": 6, "title": "Government of Mali launches data center in Bamako. \u003cp\u003eData center designed to meet Tier III standards\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#f4b000", "font": {"color": "white"}, "id": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "label": "Government / Mali / Bamako", "physics": true, "shape": "dot", "size": 61, "title": "Government / Mali / Bamako (5 signals)"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cybastion-to-build-20mw-data-center-in-gabon/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cybastion-to-build-20mw-data-center-in-gabon/", "physics": true, "shape": "dot", "size": 6, "title": "Cybastion to build 20MW data center in Gabon. \u003cp\u003eWorking with Gabonese government and Cisco on project\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/plan-for-213mw-data-center-blocked-by-councilors-in-edinburgh-scotland/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/plan-for-213mw-data-center-blocked-by-councilors-in-edinburgh-scotland/", "physics": true, "shape": "dot", "size": 6, "title": "Plan for 213MW data center blocked by councilors in Edinburgh, Scotland. \u003cp\u003eScheme had been recommended for approval\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/local-authorities-in-ashville-ohio-deny-annexation-request-for-data-center-project/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/local-authorities-in-ashville-ohio-deny-annexation-request-for-data-center-project/", "physics": true, "shape": "dot", "size": 6, "title": "Local authorities in Ashville, Ohio, deny annexation request for data center project. \u003cp\u003eUnclear how this will impact EdgeConneX\u0027s plans\u003c/p\u003e"}, {"borderWidth": 0, "borderWidthSelected": 0, "color": "#8ecae6", "font": {"color": "white"}, "id": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ta-realty-sells-two-data-center-buildings-in-leesburg-virginia/", "label": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ta-realty-sells-two-data-center-buildings-in-leesburg-virginia/", "physics": true, "shape": "dot", "size": 6, "title": "TA Realty sells two data center buildings in Leesburg, Virginia. \u003cp\u003eFirst of five fully leased buildings at campus\u003c/p\u003e"}]);
                  edges = new vis.DataSet([{"color": "rgba(244, 176, 0, 0.4)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/inferencemax-open-source-inference", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 0.3)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04184v1", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04256v1", "value": 0.6965925255207819, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04184v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04197v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04206v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04208v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04212v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04215v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04224v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04252v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04256v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04265v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04288v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04291v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04296v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04297v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04304v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 0.3)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04306v1", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04398v1", "value": 0.6953947635674054, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04306v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(14, 17, 23, 0.3)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04337v1", "smooth": false, "to": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04340v1", "value": 0.7405960531106424, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04337v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04340v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04344v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04360v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04361v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04380v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04396v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 0.4)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.04398v1", "smooth": false, "to": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "#ff9500", "dashes": true, "from": "cluster_36675d2d-fb7c-4981-a959-f17f2edd4531", "smooth": false, "to": "collapsed_36675d2d-fb7c-4981-a959-f17f2edd4531", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/californian-senator-proposes-bill-to-create-new-rate-class-for-large-load-data-centers/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tennessee-utility-tva-projects-data-center-load-to-double-across-service-area-by-2030/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/multi-gigawatt-data-center-campus-planned-in-east-texas/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/tsmc-to-produce-3nm-ai-chips-at-second-fab-in-kumamoto-japan/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/denmarks-thylander-secures-outside-investors-for-data-center-venture/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/aws-has-never-retired-an-nvidia-a100-server-ceo-matt-garman-claims/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/nvidia-prologis-epri-infrapartners-target-prefab-data-centers-at-substation-sites/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/oracle-nabs-881m-cloud-contract-from-us-air-force/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ai-compute-company-subgen-ai-signs-cloud-agreement-with-alibaba-cloud-netherlands/", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/how-ai-labs-are-solving-the-power", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/microsofts-ai-strategy-deconstructed", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/aws-trainium3-deep-dive-a-potential", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/tpuv7-google-takes-a-swing-at-the", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/xais-colossus-2-first-gigawatt-datacenter", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/another-giant-leap-the-rubin-cpx-specialized-accelerator-rack", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/huawei-ascend-production-ramp", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://semianalysis.substack.com/feed::https://newsletter.semianalysis.com/p/h100-vs-gb200-nvl72-training-benchmarks", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2510.26275v3", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://rss.arxiv.org/rss/cs.AI::oai:arXiv.org:2602.03969v1", "smooth": false, "to": "cluster_3990ff7b-3708-4ab3-b7c7-592295cf065c", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/government-of-mali-launches-data-center-in-bamako/", "smooth": false, "to": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/cybastion-to-build-20mw-data-center-in-gabon/", "smooth": false, "to": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/plan-for-213mw-data-center-blocked-by-councilors-in-edinburgh-scotland/", "smooth": false, "to": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/local-authorities-in-ashville-ohio-deny-annexation-request-for-data-center-project/", "smooth": false, "to": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "value": 0.9, "width": 1}, {"color": "rgba(244, 176, 0, 1.0)", "from": "https://www.datacenterdynamics.com/rss/::https://www.datacenterdynamics.com/en/news/ta-realty-sells-two-data-center-buildings-in-leesburg-virginia/", "smooth": false, "to": "cluster_a8706ae0-3f27-4f2d-a154-213bbf634609", "value": 0.9, "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"borderWidth": 0, "borderWidthSelected": 0, "chosen": {"node": false, "label": false}, "font": {"strokeWidth": 0}}, "interaction": {"hover": true, "hoverConnectedEdges": false, "selectConnectedEdges": false, "dragNodes": true, "dragView": true, "zoomView": true}, "physics": {"enabled": true, "stabilization": {"enabled": true, "iterations": 200, "updateInterval": 25, "fit": true}, "barnesHut": {"gravitationalConstant": -8000, "centralGravity": 0.3, "springLength": 150, "springConstant": 0.04, "damping": 0.09, "avoidOverlap": 0.5}, "solver": "barnesHut"}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    
    <script type="text/javascript">
        var selectedNode = null;
        var physicsDisabled = false;
        
        // Disable physics after stabilization so nodes stay where moved
        network.once("stabilizationIterationsDone", function() {
            network.setOptions({ physics: { enabled: false } });
            physicsDisabled = true;
        });
        
        // When dragging a cluster node, move all connected signal nodes with it
        var dragStartPositions = {};
        var clusterStartPosition = {};
        var isDraggingCluster = false;
        
        network.on("dragStart", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                
                // Check if this is a cluster node
                if (nodeId.startsWith('cluster_')) {
                    isDraggingCluster = true;
                    // Store initial position of cluster
                    clusterStartPosition = network.getPositions([nodeId])[nodeId];
                    
                    // Get all connected signal nodes
                    var connectedNodes = network.getConnectedNodes(nodeId);
                    dragStartPositions = {};
                    
                    connectedNodes.forEach(function(connectedId) {
                        if (!connectedId.startsWith('cluster_')) {
                            dragStartPositions[connectedId] = network.getPositions([connectedId])[connectedId];
                        }
                    });
                } else {
                    // Dragging a signal node - allow independent movement
                    isDraggingCluster = false;
                }
            }
        });
        
        network.on("dragging", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                
                // If dragging a cluster, move connected signals
                if (isDraggingCluster && nodeId.startsWith('cluster_') && Object.keys(dragStartPositions).length > 0) {
                    var currentPos = network.getPositions([nodeId])[nodeId];
                    var dx = currentPos.x - clusterStartPosition.x;
                    var dy = currentPos.y - clusterStartPosition.y;
                    
                    // Move all connected signal nodes by the same offset
                    for (var connectedId in dragStartPositions) {
                        var oldPos = dragStartPositions[connectedId];
                        var newX = oldPos.x + dx;
                        var newY = oldPos.y + dy;
                        network.moveNode(connectedId, newX, newY);
                    }
                }
                // If dragging a signal node, it moves independently (default behavior)
            }
        });
        
        network.on("dragEnd", function(params) {
            // Clear drag state
            dragStartPositions = {};
            clusterStartPosition = {};
            isDraggingCluster = false;
        });
        
        network.on("click", function(params) {
            if (params.nodes.length > 0) {
                var nodeId = params.nodes[0];
                var node = network.body.data.nodes.get(nodeId);
                
                // Create persistent popup
                var popup = document.createElement('div');
                popup.id = 'node-popup';
                popup.style.position = 'fixed';
                popup.style.background = '#1e1e1e';
                popup.style.color = 'white';
                popup.style.padding = '15px';
                popup.style.borderRadius = '8px';
                popup.style.maxWidth = '400px';
                popup.style.border = '2px solid #f4b000';
                popup.style.zIndex = '10000';
                popup.style.top = '50%';
                popup.style.left = '50%';
                popup.style.transform = 'translate(-50%, -50%)';
                popup.style.boxShadow = '0 4px 20px rgba(0,0,0,0.5)';
                popup.innerHTML = '<strong>' + (node.label || 'Signal') + '</strong><br><br>' + 
                                 (node.title || 'No content') + 
                                 '<br><br><small style="color: #888;">Click anywhere to close</small>';
                
                // Remove existing popup if any
                var existing = document.getElementById('node-popup');
                if (existing) existing.remove();
                
                document.body.appendChild(popup);
                selectedNode = nodeId;
            } else {
                // Click on empty space - remove popup
                var popup = document.getElementById('node-popup');
                if (popup) popup.remove();
                selectedNode = null;
            }
        });
    </script>
    </body>
</html>